{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import acos, degrees\n",
    "from scipy.signal import find_peaks\n",
    "import os.path\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import entropy\n",
    "import pylab as pl\n",
    "from numpy.fft import fft\n",
    "from scipy import stats\n",
    "import numpy\n",
    "from scipy import signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_width = 250\n",
    "#centr_rang = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt(a, b, c):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "    math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getridofAngleJumps(alpha):\n",
    "    alpha_rad = [x*(np.pi)/180 for x in alpha]\n",
    "    alpha_rad = np.array(alpha_rad)\n",
    "    alpha_rad[~np.isnan(alpha_rad)] = np.unwrap(alpha_rad[~np.isnan(alpha_rad)])\n",
    "    alpha_unwrap= np.degrees(alpha_rad)\n",
    "    #alpha_unwrap_within_limit = alpha_unwrap%(360)\n",
    "    return alpha_unwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to get rid of ugly jumps due to angle range [0-360], input alpha that is a list of angles\n",
    "#def getridofAngleJumps(x):\n",
    "#    n = [ 0, *np.diff(x) ]\n",
    "##    #get rid of negative jumps\n",
    "#    for i in range(len(n)):\n",
    "#        if n[i] < -300:\n",
    "#            while x[i] < 200: #or x[i] == 'NaN':\n",
    "#                x[i] = x[i]+360\n",
    "#                i += 1\n",
    "#                if x[i] == 'NaN':\n",
    "#                    i += 1\n",
    "#    #get rid also of positive jumps\n",
    "##        if n[i] > 300:\n",
    "##            while x[i] > 300:\n",
    "##                x[i] = x[i]-360\n",
    "##                i += 1        \n",
    "#    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_acausal(x,frequency = 0.300):\n",
    "    #b, a = signal.butter(8, 0.150)\n",
    "    sos = signal.butter(4, frequency, output='sos')\n",
    "    y = signal.sosfiltfilt(sos, x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=20,window='hanning'):\n",
    "#    \"\"\"smooth the data using a window with requested size.\n",
    "#    \n",
    "#    This method is based on the convolution of a scaled window with the signal.\n",
    "#    The signal is prepared by introducing reflected copies of the signal \n",
    "#    (with the window size) in both ends so that transient parts are minimized\n",
    "#    in the begining and end part of the output signal.\n",
    "#    \n",
    "#    input:\n",
    "#        x: the input signal \n",
    "#        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "#        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "#            flat window will produce a moving average smoothing.\n",
    "#\n",
    "#    output:\n",
    "#        the smoothed signal\n",
    "#        \n",
    "#    example:\n",
    "#\n",
    "#    t=linspace(-2,2,0.1)\n",
    "#    y=smooth(x)\n",
    "#    \n",
    "#    \n",
    "#    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "#    scipy.signal.lfilter\n",
    " \n",
    "#    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "#    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract RidgeX trajectory from excel file\n",
    "def RidgeX_excel_to_array_preprocessed(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    RidgeX = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    #take just numeric values\n",
    "    RidgeX=pd.to_numeric(RidgeX.iloc[:,0])\n",
    "\n",
    " \n",
    "    return RidgeX.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract RidgeX trajectory from excel file\n",
    "def BodyAxis_HeadTail_excel_to_array_preprocessed(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    File_columns = pd.read_csv(file_path[trial_no])\n",
    "    \n",
    "    #take just numeric values\n",
    "    BodyAxis=pd.to_numeric(File_columns.iloc[:,0])\n",
    "    Rear_X = pd.to_numeric(File_columns.iloc[:,1])\n",
    "    Rear_Y = pd.to_numeric(File_columns.iloc[:,2])\n",
    "    Head_X = pd.to_numeric(File_columns.iloc[:,3])\n",
    "    Head_Y = pd.to_numeric(File_columns.iloc[:,4])\n",
    " \n",
    "    return BodyAxis.values, Rear_X, Rear_Y, Head_X, Head_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def plot_TailAngle(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.8':'tail3_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_x=pd.to_numeric(df.tail3_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_y=pd.to_numeric(df.tail3_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_lik=pd.to_numeric(df.tail3_lik[c-chunk_width:c+chunk_width])\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_x.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_y.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        #x1,y1=df.tail1_x[i],df.tail1_y[i]\n",
    "        vertical = np.array([df.tail1_x[i],df.tail1_y[i]+10])\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])    \n",
    "        tail3 = np.array([df.tail3_x[i],df.tail3_y[i]])\n",
    "    \n",
    "\n",
    "    #Change below to decide 3 points to determine angle\n",
    "        angle = angle3pt(tail2, tail1, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def plot_TailAngleTC(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.8':'tail3_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_x=pd.to_numeric(df.tail3_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_y=pd.to_numeric(df.tail3_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_lik=pd.to_numeric(df.tail3_lik[c-chunk_width:c+chunk_width])\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_x.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_y.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        #x1,y1=df.tail1_x[i],df.tail1_y[i]\n",
    "        vertical = np.array([df.tail1_x[i],df.tail1_y[i]-10])\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])    \n",
    "        tail3 = np.array([df.tail3_x[i],df.tail3_y[i]])\n",
    "    \n",
    "\n",
    "    #Change below to decide 3 points to determine angle\n",
    "        angle = angle3pt(tail2, tail1, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail XY traj\n",
    "def extract_TailAngleTC_XY(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.8':'tail3_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.8#05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    tail1_array=[]\n",
    "    tail2_array=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])\n",
    "        #Append\n",
    "        tail1_array.append(tail1)\n",
    "        tail2_array.append(tail2)\n",
    "\n",
    "    return tail1_array, tail2_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def extract_NoseAngleTC_XY(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.30':'nose_x',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.31':'nose_y',\n",
    "                          'DLC_resnet50_Ridge_walk_TCJun8shuffle1_1000000.32':'nose_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.nose_x=pd.to_numeric(df.nose_x[c-chunk_width:c+chunk_width])\n",
    "    df.nose_y=pd.to_numeric(df.nose_y[c-chunk_width:c+chunk_width])\n",
    "    df.nose_lik=pd.to_numeric(df.nose_lik[c-chunk_width:c+chunk_width])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.8#0.05\n",
    "    df.nose_x.where((df.nose_x>lik_thresh),np.NaN,inplace=True)\n",
    "    df.nose_y.where((df.nose_y>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    nose_array=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        nose = np.array([df.nose_x[i],df.nose_y[i]])\n",
    "        #Append\n",
    "        nose_array.append(nose)\n",
    "\n",
    "    return nose_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_RPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.36':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.37':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.38':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.39':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.40':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.41':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RA_x[i],df.RA_y[i]+10])\n",
    "        RA = np.array([df.RA_x[i],df.RA_y[i]])\n",
    "        RP = np.array([df.RP_x[i],df.RP_y[i]])\n",
    "\n",
    "        angle = angle3pt(RP, RA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_LPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.27':'LA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.28':'LA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.29':'LA_lik',\n",
    "                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.36':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.37':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.38':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.39':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.40':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.41':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.LA_x=pd.to_numeric(df.LA_x[2:])\n",
    "\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.LA_y=pd.to_numeric(df.LA_y[2:])\n",
    "\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    \n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.LA_lik=pd.to_numeric(df.LA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_x.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_y.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.LA_x[i],df.LA_y[i]+10])\n",
    "        LA = np.array([df.LA_x[i],df.LA_y[i]])\n",
    "        LP = np.array([df.LP_x[i],df.LP_y[i]])\n",
    "\n",
    "        angle = angle3pt(LP, LA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_HipAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.30':'LH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.31':'LH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.32':'LH_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.33':'RH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.34':'RH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.35':'RH_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.LH_x=pd.to_numeric(df.LH_x[2:])\n",
    "    df.LH_y=pd.to_numeric(df.LH_y[2:])\n",
    "    df.RH_x=pd.to_numeric(df.RH_x[2:])\n",
    "    df.RH_y=pd.to_numeric(df.RH_y[2:])\n",
    "    df.RH_lik=pd.to_numeric(df.RH_lik[2:])\n",
    "    df.LH_lik=pd.to_numeric(df.LH_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.LH_x.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LH_y.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_x.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_y.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    LH_x =  df.LH_x\n",
    "    LH_y =  df.LH_y\n",
    "    RH_x =  df.RH_x    \n",
    "    RH_y =  df.RH_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RH_x[i],df.RH_y[i]+10])\n",
    "        RH = np.array([df.RH_x[i],df.RH_y[i]])\n",
    "        LH = np.array([df.LH_x[i],df.LH_y[i]])\n",
    "\n",
    "        angle = angle3pt(LH, RH, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract centroid X Y trajectory\n",
    "def extract_Centroid(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    CentroidXY = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    CentroidXY.rename(columns={'NaN':'X',\n",
    "                              'NaN.1':'Y'}, \n",
    "                     inplace=True)\n",
    "    #take just numeric values\n",
    "    CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
    "    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "    CentroidX =  np.array(CentroidXY.Centroid_x)\n",
    "    CentroidY =  np.array(CentroidXY.Centroid_y)\n",
    "    return CentroidX, CentroidY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delay(a, b):\n",
    "    corr_a_b = np.correlate(a-np.mean(a), b-np.mean(b), mode = 'full')\n",
    "    delay = np.where(corr_a_b == numpy.amin(corr_a_b))# -(np.size(corr_a_b)+1)/2\n",
    "    return delay[0]-(np.size(corr_a_b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_Centroid_edge_dist(file_path, chunk_width, i):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "\n",
    "##Open Centroid file from top camera\n",
    "#CentroidXY = pd.read_csv('C:/Users/Salvo/Desktop/Ridge/DLC_videos/Videos_to_analyzeDLC/Ridge_MiceS20-S24_16thApril/perturbation_8mm_1/8_S22/Centroid.csv')\n",
    "\n",
    "    #Select 1st column csv file\n",
    "    matrix2 = df[df.columns[0]]#.as_matrix()\n",
    "    Centroid1stcol = matrix2.tolist() #file 1st column\n",
    "\n",
    "\n",
    "#    CentroidXY.rename(columns={'NaN':'dist'}, \n",
    "#                     inplace=True)\n",
    "    #take just numeric values\n",
    "    Centroid1stcol = np.array(pd.to_numeric(Centroid1stcol))\n",
    "#    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "#    CentroidX =  CentroidXY.Centroid_x\n",
    "#    CentroidY =  CentroidXY.Centroid_y\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width:tot_peaks+centr_rang-chunk_width]#-[CentroidX[tot_peaks]]\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width-100:tot_peaks-100]-[CentroidX[tot_peaks-100]]\n",
    "    return smooth(Centroid1stcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#np.arange(len(file_to_open)-25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i\n",
    "\n",
    "#firstNonNan(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HIST_MI_2_var(a, b):\n",
    "    fig = plt.figure(figsize=(10,14))\n",
    "    ax1 = plt.subplot(311)\n",
    "    ax2 = plt.subplot(312)\n",
    "    hist_centr = ax1.hist(a, density=True, bins=30, color = 'orange')  # `density=False` would make counts\n",
    "    hist_tail = ax2.hist(b, density=True, bins=30, color = 'blue')  # `density=False` would make counts\n",
    "#    ent_cent = entropy(hist_centr[0], base=2)\n",
    "#    ent_tail = entropy(hist_tail[0], base=2)\n",
    "    MI_cent_tail = metrics.mutual_info_score(hist_centr[0], hist_tail[0])\n",
    "    return MI_cent_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_delay_array(var1, var2):\n",
    "    var1 = var1[~np.isnan(var1)] #centroid\n",
    "    var2 = var2[~np.isnan(var2)] #TA\n",
    "    #take the mean out\n",
    "#    var1 = var1-np.mean(var1)\n",
    "#    var2 = var2-np.mean(var2)\n",
    "\n",
    "    corr_a_b = np.correlate(var1, var2, mode = 'full')\n",
    "    #norm_corr_a_b = np.correlate(var2/np.std(var2), var1/np.std(var1), mode = 'full')\n",
    "    cc_trace_midpoint = len(corr_a_b)\n",
    "    delay = np.argmax(abs(corr_a_b))-(cc_trace_midpoint/2)+1 #Get the delay of the absolute max peak\n",
    "    max_peak = max(corr_a_b)#, key=abs)\n",
    "#    max_peak = abs(max(corr_a_b, key=abs))\n",
    "    return delay, max_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(chunk_width, data):\n",
    "    # Number of sample points\n",
    "    N = chunk_width*2\n",
    "    # sample spacing\n",
    "    T = 1/300\n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "    y = data\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0, 1/(2*T), N//2)\n",
    "#    plt.plot(xf, 2/N * np.abs(yf[0:N//2]))\n",
    "#    plt.grid()\n",
    "#    plt.show()\n",
    "    return xf, yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks_extractchunk(x_diff, x, y, z, w, w_x, t, other_step_x, ba, cent_dist, threshold_height, chunk_width_step):\n",
    "    ba_diff = np.diff(ba)\n",
    "    peaks, _ = find_peaks(ba, height=threshold_height, distance = 50, prominence = 1)\n",
    "    out_step = []\n",
    "    out_TA = []\n",
    "    out_HA = []\n",
    "    out_cent = []\n",
    "    out_RstepAng = []\n",
    "    out_cent_X = []\n",
    "    out_ba = []\n",
    "    out_contra_step_x = []\n",
    "    out_cent_dist = []\n",
    "    for i in np.arange(len(peaks)):\n",
    "        chunk_trial_step = x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_contra_step = other_step_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA = y[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_HA = z[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_cent = w[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_centX = w_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_RstepAng = t[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_BA = ba[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_CentDist = cent_dist[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        \n",
    "\n",
    "        out_step.append(chunk_trial_step)\n",
    "        out_TA.append(chunk_trial_TA)\n",
    "        out_HA.append(chunk_trial_HA)\n",
    "        out_cent.append(chunk_trial_cent)\n",
    "        out_cent_X.append(chunk_trial_centX)\n",
    "        out_ba.append(chunk_trial_BA)\n",
    "        out_contra_step_x.append(chunk_trial_contra_step)\n",
    "        out_cent_dist.append(chunk_trial_CentDist)\n",
    "        #transpose all traces of step angle greater than 360 back to 0\n",
    "        if np.nanmean(chunk_trial_RstepAng) > 250:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng-360)\n",
    "        elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng+360)   \n",
    "        else:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng)\n",
    "\n",
    "\n",
    "    \n",
    "    return out_step, out_TA, out_HA, out_cent, out_cent_X, out_RstepAng, out_contra_step_x, out_ba, out_cent_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as mpl_text\n",
    "\n",
    "class AnyObject(object):\n",
    "    def __init__(self, text, color):\n",
    "        self.my_text = text\n",
    "        self.my_color = color\n",
    "\n",
    "class AnyObjectHandler(object):\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        print(orig_handle)\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        width, height = handlebox.width, handlebox.height\n",
    "        patch = mpl_text.Text(x=0, y=0, text=orig_handle.my_text, color=orig_handle.my_color, verticalalignment=u'baseline', \n",
    "                                horizontalalignment=u'left', multialignment=None, \n",
    "                                fontproperties=None, rotation=45, linespacing=None, \n",
    "                                rotation_mode=None)\n",
    "        handlebox.add_artist(patch)\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def delete_bad_traces_FromList(Traces_List, idx_to_eliminate):\n",
    "    for l in np.arange(len(idx_to_eliminate)):\n",
    "        for i in np.arange(len(Traces_List)):\n",
    "            for j in np.arange(len(Traces_List[i])):\n",
    "                if len(Traces_List[i][j]) == 200:\n",
    "                    if i == idx_to_eliminate[l][0] and j == idx_to_eliminate[l][1]:\n",
    "                        Traces_List[i][j] = [] \n",
    "    return Traces_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_trace(trace):\n",
    "    if np.nanmean(trace) <-50:\n",
    "        trace = trace + 360\n",
    "#    if np.nanmean(trace) >400:\n",
    "#        trace = trace - 360\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_trace_within_0_to_150(trace):\n",
    "    if np.nanmean(trace) <-50:\n",
    "        trace = trace + 360\n",
    "        if np.nanmean(trace) <-50:\n",
    "            trace = trace + 360\n",
    "#    elif np.nanmean(trace[0:60]) >150:\n",
    "#        trace = []\n",
    "    else:\n",
    "        trace = trace\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(RidgeX_ExcelList_to_open), len(TA_ExcelList_to_open), len(TA_TopCam_ExcelList_to_open), len(Centroid_ExcelList_to_open), len(BodyAxis_ExcelList_to_open))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_key_path = ['*45mm*']#, '*5mm*', '*8mm*', '*10mm*', '*15mm*', '*45mm*']\n",
    "# search_key = ['45mm']#, '5mm', '8mm', '10mm', '15mm', '45mm']\n",
    "\n",
    "# #dict_ridge_all = defaultdict(dict)\n",
    "# for j in np.arange(len(search_key)):\n",
    "#     #fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "#     data_location = \"R://UusisaariU//PROCESSED_DATA_BACKUPS//nRIM_MEMBERS//Salvo//RD_all_cond//RD_all_cond_analyzed//\"\n",
    "#     RidgeX_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Ridge_X//*.csv'))\n",
    "#     TA_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'side_cam//*//*.csv'))\n",
    "#     TA_TopCam_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'top_cam//*//*.csv'))\n",
    "#     Centroid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Centroid_XY//*.csv'))\n",
    "#     BodyAxis_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis//*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(arr):\n",
    "#     mask = np.isnan(arr)\n",
    "#     idx = np.where(~mask,np.arange(mask.size),0)\n",
    "#     np.maximum.accumulate(idx, out=idx)\n",
    "#     arr[mask] = arr[idx]\n",
    "    df = pd.DataFrame(data=arr.flatten())\n",
    "    df = df.fillna(value=None, method='backfill', axis=None, limit=70, downcast=None)\n",
    "    arr = df.values\n",
    "#    print(type(arr))\n",
    "    return arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to extract angle using 3 points coordinate\n",
    "# def angle3pt_cent_TA(B, C):\n",
    "# #    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "# #        Returns a float between 0.0 and 360.0\"\"\"\n",
    "#     ang_traj = []\n",
    "#     #print(len(B[0]))\n",
    "#     for i in np.arange(len(B[0])):\n",
    "#         a = [B[0][i], B[1][i]-10]\n",
    "#         b = [B[0][i], B[1][i]]#[B[0][i], B[1][i]]\n",
    "#         c = C[i]\n",
    "#         #print(a, b, c)\n",
    "#         ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "#         ang_traj.append(ang)# + 360 if ang < 0 else ang)\n",
    "#     #Apply smooth\n",
    "#     ang_traj = np.array(ang_traj)#smooth(np.array(ang_traj))\n",
    "#     return ang_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle3pt(a, b, c):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from a to c around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "        math.atan2(c[1] - b[1], c[0] - b[0]) - math.atan2(a[1] - b[1], a[0] - b[0]))\n",
    "    return ang# + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle2pt_cent_TA(B, C):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang_traj = []\n",
    "    for i in np.arange(len(C[0])):\n",
    "        a = [C[0][i]+25, C[1][i]-10] #Offset btw Bonsai and DLC frame of analysis is 25\n",
    "        b = [C[0][i]+25, C[1][i]]\n",
    "        c = B[i]\n",
    "        #print(a,b,c)\n",
    "        ang = angle3pt(a, b, c)\n",
    "        ang_traj.append(ang)# + 360 if ang < 0 else ang)\n",
    "    #Apply smooth\n",
    "    ang_traj = np.array(ang_traj)#smooth(np.array(ang_traj))\n",
    "    return ang_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle2pt_Tail_Nose(B, C):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang_traj = []\n",
    "    for i in np.arange(len(B)):\n",
    "        a = [C[i][0], C[i][1]-10] #no need for offset as both measuremntes are from DLC\n",
    "        b = C[i]\n",
    "        c = B[i]\n",
    "        #print(a,b,c)\n",
    "        ang = angle3pt(a, b, c)\n",
    "        ang_traj.append(ang)# + 360 if ang < 0 else ang)\n",
    "    #Apply smooth\n",
    "    ang_traj = np.array(ang_traj)#smooth(np.array(ang_traj))\n",
    "    return ang_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt_cent_TA(A, B, C):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang_traj = []\n",
    "    for i in np.arange(len(C[0])):\n",
    "        a = A[i] \n",
    "        b = B[i]\n",
    "        c = [C[0][i]+25, C[1][i]] #Offset btw Bonsai and DLC frame of analysis is 25\n",
    "        #print(a,b,c)\n",
    "        ang = angle3pt(a, b, c)\n",
    "        ang_traj.append(ang)# + 360 if ang < 0 else ang)\n",
    "    #Apply smooth\n",
    "    ang_traj = np.array(ang_traj)#smooth(np.array(ang_traj))\n",
    "    return ang_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt_nose_cent_tail(A, B, C):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang_traj = []\n",
    "    for i in np.arange(len(B[0])):\n",
    "        a = A[i] #Offset btw Bonsai and DLC frame of analysis is 25\n",
    "        b = [B[0][i]+25, B[1][i]]\n",
    "        c = C[i]\n",
    "        #print(a,b,c)\n",
    "        ang = angle3pt(a, b, c)\n",
    "        ang_traj.append(ang)# + 360 if ang < 0 else ang)\n",
    "    #Apply smooth\n",
    "    ang_traj = np.array(ang_traj)#smooth(np.array(ang_traj))\n",
    "    return ang_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_key_path = ['*4mm*', '*_5mm*', '*8mm*', '*10mm*', '*Wei*']\n",
    "# search_key = ['4mm', '5mm', '8mm', '10mm', 'Wei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "### Organize all data into python dict\n",
    "from collections import defaultdict\n",
    "\n",
    "search_key_path = ['*4mm*', '*_5mm*', '*8mm*', '*10mm*', '*45mm*']#'*15mm*', '*45mm*'] #I added _ to 5mm to distinguish it from 15,45\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']#'15mm', '45mm']\n",
    "\n",
    "dict_ridge_all = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    data_location = \"R://UusisaariU//PROCESSED_DATA_BACKUPS//nRIM_MEMBERS//Salvo//RD_all_cond//RD_all_cond_analyzed//\"\n",
    "    RidgeX_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Ridge_X//*.csv'))\n",
    "    TA_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'side_cam//*//*.csv'))\n",
    "    TA_TopCam_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'top_cam//*//*.csv'))\n",
    "    Centroid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Centroid_XY//*.csv'))\n",
    "    BodyAxis_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis//*.csv'))\n",
    "    CentDistMid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Cent_dst_to_mdline//*.csv'))\n",
    "    BodyAxisHeadTail_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis_HeadTail//*.csv'))\n",
    "\n",
    "    for i in np.arange(len(RidgeX_ExcelList_to_open)): # len(peaks)\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "        key_file_name = os.path.basename(RidgeX_ExcelList_to_open[i])\n",
    "#        ax1.set_title(key_file_name)\n",
    "#         print(key_file_name)\n",
    "        #Extract arrays\n",
    "        RidgeX_traj = RidgeX_excel_to_array_preprocessed(RidgeX_ExcelList_to_open, chunk_width, i)\n",
    "        CentroidX_traj, CentroidY_traj = extract_Centroid(Centroid_ExcelList_to_open, chunk_width, i)\n",
    "        BodyAxis_traj = RidgeX_excel_to_array_preprocessed(BodyAxis_ExcelList_to_open, chunk_width, i)\n",
    "        CentMidline_traj = RidgeX_excel_to_array_preprocessed(CentDistMid_ExcelList_to_open, chunk_width, i)\n",
    "        #Extract traces of Centroid and Tail Angle around the time frame when the mouse is at the ridge center\n",
    "        a = firstNonNan(CentroidX_traj)\n",
    "        b = round((np.size(CentroidX_traj) - np.count_nonzero(np.isnan(CentroidX_traj)))/2)\n",
    "        c = a + b\n",
    "\n",
    "        #Take tail angle traj after extracting chunk of traj of interest around c\n",
    "        TailAngle_traj = plot_TailAngle(TA_ExcelList_to_open, chunk_width, i, c)\n",
    "        TailAngle_trajTC = plot_TailAngleTC(TA_TopCam_ExcelList_to_open, chunk_width, i, c)\n",
    "        \n",
    "        #Take angle btw centroid and rear from topcam extraction\n",
    "        BodyAxis_new_traj, Rear_X, Rear_Y, \\\n",
    "        Head_X, Head_Y = BodyAxis_HeadTail_excel_to_array_preprocessed(BodyAxisHeadTail_ExcelList_to_open, chunk_width, i)\n",
    "        #print(BodyAxis_new_traj)\n",
    "        TA_1_topcam_XY, TA_2_topcam_XY = extract_TailAngleTC_XY(TA_TopCam_ExcelList_to_open, chunk_width, i, c)\n",
    "        Nose_topcam_XY = extract_NoseAngleTC_XY(TA_TopCam_ExcelList_to_open, chunk_width, i, c)\n",
    "        Cent_XY = np.array([CentroidX_traj, CentroidY_traj])\n",
    "        Head_XY = np.array([Head_X, Head_Y])\n",
    "        Rear_XY = np.array([Rear_X, Rear_Y])\n",
    "        Angle_Cent_TailBase = angle2pt_cent_TA(TA_1_topcam_XY, Cent_XY)\n",
    "        #Take angle btw centroid and nose from topcam extraction\n",
    "        Angle_Cent_Nose = angle2pt_cent_TA(Nose_topcam_XY, Cent_XY)\n",
    "        #Take angle btw centroid and tail base 1 and tail 2\n",
    "        Angle_Cent_Tail1_Tail2 = angle3pt_cent_TA(TA_2_topcam_XY, TA_1_topcam_XY, Cent_XY)\n",
    "        #Take angle btw nose and tail base 1\n",
    "        Angle_Nose_Tail1 = angle2pt_Tail_Nose(Nose_topcam_XY, TA_1_topcam_XY)\n",
    "        #Take angle btw nose cent and tail base 1 \n",
    "        Angle_Nose_Cent_Tail1 = angle3pt_nose_cent_tail(TA_1_topcam_XY, Cent_XY, Nose_topcam_XY)\n",
    "        \n",
    "\n",
    "        \n",
    "#         #Get chunk of traces\n",
    "        RidgeX_traj_chunk = RidgeX_traj[c-chunk_width:c+chunk_width]\n",
    "        TailAngle_traj_chunk = TailAngle_traj[c-chunk_width:c+chunk_width]\n",
    "        TailAngle_trajTC_chunk = TailAngle_trajTC[c-chunk_width:c+chunk_width]\n",
    "        Angle_Cent_TailBase_chunk = Angle_Cent_TailBase[c-chunk_width:c+chunk_width]\n",
    "        Angle_Cent_Nose_chunk = Angle_Cent_Nose[c-chunk_width:c+chunk_width]\n",
    "        Angle_Cent_Tail1_Tail2_chunk = Angle_Cent_Tail1_Tail2[c-chunk_width:c+chunk_width]\n",
    "        Angle_Nose_Cent_Tail1_chunk = Angle_Nose_Cent_Tail1[c-chunk_width:c+chunk_width]\n",
    "        Angle_Nose_Tail1_chunk = Angle_Nose_Tail1[c-chunk_width:c+chunk_width]\n",
    "        \n",
    "\n",
    "         #TailAngle_traj_chunk_corrected = check_trace(TailAngle_traj_chunk)\n",
    "        CentroidX_traj_chunk = (CentroidX_traj[c-chunk_width:c+chunk_width])\n",
    "        CentroidY_traj_chunk = (CentroidY_traj[c-chunk_width:c+chunk_width])\n",
    "        BodyAxis_traj_chunk = BodyAxis_traj[c-chunk_width:c+chunk_width]\n",
    "        BodyAxis_new_traj_chunk = BodyAxis_new_traj[c-chunk_width:c+chunk_width]\n",
    "        CentMidline_traj_chunk = (CentMidline_traj[c-chunk_width:c+chunk_width])\n",
    "        HipAngle_traj = plot_HipAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        HipAngle_traj_chunk = HipAngle_traj[c-chunk_width:c+chunk_width]\n",
    "\n",
    "         #Compute R and L step \n",
    "        [RPAngle_traj, RP_x, LP_x]   = plot_RPAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        RP_x = RP_x[c-chunk_width:c+chunk_width]\n",
    "        LP_x = LP_x[c-chunk_width:c+chunk_width]   \n",
    "        RPAngle_traj_chunk = fill_nan(RPAngle_traj[c-chunk_width:c+chunk_width])\n",
    "\n",
    "        #divide trial into step-based chunks RIGHT\n",
    "        x_r = RP_x-np.nanmean(RP_x)\n",
    "        x_l = LP_x-np.nanmean(LP_x)\n",
    "        x_r_diff = np.diff(RP_x-np.nanmean(RP_x))\n",
    "        x_l_diff = np.diff(-(LP_x-np.nanmean(-LP_x)))\n",
    "        y_r = TailAngle_trajTC_chunk#-np.nanmean(TailAngle_traj)\n",
    "        y_l = TailAngle_trajTC_chunk#-np.nanmean(TailAngle_traj)\n",
    "        w = CentroidY_traj_chunk#-np.nanmean(Centroid_DIST_traj)#*50\n",
    "        z = HipAngle_traj_chunk#-np.nanmean(HipAngle_traj)\n",
    "        t = RPAngle_traj_chunk#-np.nanmean(RPAngle_traj)\n",
    "        ba = BodyAxis_new_traj#BodyAxis_traj_chunk\n",
    "        w_x = CentroidX_traj_chunk\n",
    "        w_dist = CentMidline_traj_chunk\n",
    "        step_chunk_R, TA_chunk_R, HA_chunk_R, cent_chunk_R, cent_chunk_XR, StepAngle_chunk_R, step_chunk_L_wrt_Rstep, \\\n",
    "         ba_wrt_Rstep, w_dist_Rstep = findpeaks_extractchunk(x_r_diff, x_r, y_r, z, w, w_x, t, x_l, ba, w_dist, 0.9, chunk_width//2)\n",
    "\n",
    "        #divide trial into step-based chunks LEFT\n",
    "        step_chunk_L, TA_chunk_L, HA_chunk_L, cent_chunk_L, cent_chunk_XL, StepAngle_chunk_L, step_chunk_R_wrt_Lstep, \\\n",
    "         ba_wrt_Lstep, w_dist_Lstep = findpeaks_extractchunk(x_l_diff, x_l, y_l, z, w, w_x, t, x_r, ba, w_dist, 0.9, chunk_width//2)\n",
    "\n",
    "\n",
    "        #Decide here what variables to plot in the three figures\n",
    "        var1 = np.array(RidgeX_traj_chunk)\n",
    "        var2 = np.array(TailAngle_trajTC_chunk)# TailAngle_traj_chunk\n",
    "        var3 = np.array(CentroidX_traj_chunk) \n",
    "        var4 = step_chunk_R\n",
    "        var5 = TA_chunk_R\n",
    "        var6 = step_chunk_L\n",
    "        var7 = TA_chunk_L\n",
    "        var8 = StepAngle_chunk_R\n",
    "        var9 = StepAngle_chunk_L\n",
    "        var10 = cent_chunk_R #CentY\n",
    "        var11 = cent_chunk_L #CentY\n",
    "        var12 = cent_chunk_XR\n",
    "        var13 = HA_chunk_R\n",
    "        var14 = StepAngle_chunk_R\n",
    "        var15 = step_chunk_L_wrt_Rstep\n",
    "        var16 = ba_wrt_Rstep\n",
    "        var17 = ba_wrt_Lstep\n",
    "        var18 = HA_chunk_L\n",
    "        var19 = np.array(BodyAxis_new_traj_chunk)##BodyAxis_traj_chunk)\n",
    "        var20 = w_dist_Lstep\n",
    "        var21 = w_dist_Rstep\n",
    "        var22 = CentroidY_traj_chunk\n",
    "        var23 = CentMidline_traj_chunk\n",
    "        var24 = Angle_Cent_TailBase_chunk\n",
    "        var25 = Angle_Cent_Nose_chunk\n",
    "        var26 = Angle_Cent_Tail1_Tail2_chunk\n",
    "        var27 = BodyAxis_traj_chunk\n",
    "        var28 = Angle_Nose_Tail1_chunk\n",
    "        var29 = Angle_Nose_Cent_Tail1_chunk\n",
    "        var30 = Angle_Cent_Tail1_Tail2_chunk-Angle_Cent_TailBase_chunk\n",
    "\n",
    "\n",
    "#         #Make dict\n",
    "        key_file_name = os.path.basename(RidgeX_ExcelList_to_open[i])\n",
    "# #         print(key_file_name)\n",
    "        dict_ridge_all[search_key[j]][key_file_name] = [var1, var2, var3, var4, var5, var6, var7, \\\n",
    "                                                         var8, var9, var10, var11, var12, var13, var14, var15, \\\n",
    "                                                         var16, var17, var18, var19, var20, var21, var22, var23, \\\n",
    "                                                         var24, var25, var26, var27, var28, var29, var30]\n",
    "\n",
    "#       Plot traces\n",
    "        #print(var19)\n",
    "#         ax1.plot(var29, color = 'red')#-np.nanmean(Angle_Cent_TailBaseTopCam), color = 'red')\n",
    "#         ax1.plot(var30, color = 'blue')\n",
    "        #ax1.plot(var25, color = 'green')\n",
    "\n",
    "# #         bla = [i[0] for i in TA_1_topcam_XY]\n",
    "# #         ax1.plot(bla-np.nanmean(bla), color = 'blue')\n",
    "# #         ax1.plot(Cent_XY[0]-np.nanmean(Cent_XY[0]), color = 'green')\n",
    "\n",
    "#         ax1.set_title(key_file_name)\n",
    "#         print(var5)\n",
    "#         for s in np.arange(len(var5)):\n",
    "#             if len(var5):\n",
    "#                 fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "#                 ax1.plot(var5[s], color = 'red')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CentroidX_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_dict_value_ridge_pos(dict_ridge):\n",
    "    #Divide trials based on ridge position. Assign -1 for left tilt, +1 for right and 0 for no tilts. Append to 4th col\n",
    "    #Changed the threshold from 5000 to 10000 bcs M53 detected many no pert trials as pert\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "\n",
    "        ridge_array = dict_ridge[key_list[i]][0]\n",
    "        ridge_array_translated_nonNaN = ridge_array[~np.isnan(ridge_array)]\n",
    "        ridge_array_translated_nonNaN_mean_centered = ridge_array_translated_nonNaN-  \\\n",
    "        np.nanmean(smooth(ridge_array_translated_nonNaN[20:40]))\n",
    "        ridge_array_translated_int = np.trapz(smooth(ridge_array_translated_nonNaN_mean_centered, 50))\n",
    "        ridge_array_translated_nonNaN_mean_centered_diff_max = max(np.diff(ridge_array_translated_nonNaN_mean_centered))\n",
    "        if ridge_array_translated_int < -3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(-1)\n",
    "            #print(ridge_array_translated_nonNaN_mean_centered_diff_max)\n",
    "        elif ridge_array_translated_int > +3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(1)\n",
    "    #        print(ridge_array_translated_int)\n",
    "\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(0)    \n",
    "    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_pert_trials_from_dict(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    for i in np.arange(len(key_list)):\n",
    "        Ridge_classvalue = values_list[i][-1]\n",
    "        if Ridge_classvalue == 1 or Ridge_classvalue == -1:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeNaNTATraces(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is mostly NaN\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][1]\n",
    "        no_of_nan_TAtraj = list(np.isnan(TA_traj))\n",
    "        count_NaN = no_of_nan_TAtraj.count(1)\n",
    "        if count_NaN>70:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "        elif len(TA_traj) == 0:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_traces_0_360_range(dict_ridge):\n",
    "    #Transpose from dict all trials where the TA traj is outsude [0, 360] and append to 13th column \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    #dict_TA_transpose = {}\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        key_to_change = key_list[i]\n",
    "        TA_to_append = []\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            if np.nanmean(TA_traj[j])>400:\n",
    "                TA_traj_pushed_down = TA_traj[j]-360\n",
    "                TA_to_append.append(TA_traj_pushed_down)      \n",
    "            elif np.nanmean(TA_traj[j])<-100:\n",
    "                TA_traj_pushed_up = TA_traj[j]+360\n",
    "                TA_to_append.append(TA_traj_pushed_up)\n",
    "            else:\n",
    "                TA_to_append.append(TA_traj[j])\n",
    "        dict_ridge[key_to_change].append(TA_to_append)    \n",
    "\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesNON_0_360(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is outside 0 to 360 \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            #print(len(TA_traj))\n",
    "            if np.nanmean(TA_traj[j])>350:\n",
    "                TA_traj[j] = []\n",
    "            elif np.nanmean(TA_traj[j]) < 10:\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesHighDerivative(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)): # step\n",
    "            TA_diff = np.diff(TA_traj[j])\n",
    "            if np.any(TA_diff>8) or np.any(TA_diff<-8):\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_TA_ipsi_contra_within0_360_range(TA_traj):\n",
    "    if np.nanmean(TA_traj)>400:\n",
    "        TA_traj = TA_traj-360\n",
    "    elif np.nanmean(TA_traj)<-40:\n",
    "        TA_traj = TA_traj+360\n",
    "    return TA_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL):\n",
    "    TA_wrtIpsiStep = []\n",
    "    TA_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        TA_wrtIpsiStep = TA_traj_listwrtR\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        TA_wrtIpsiStep = -TA_traj_listwrtL+360\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        TA_wrtContraStep = -TA_traj_listwrtR+360\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        TA_wrtContraStep = TA_traj_listwrtL\n",
    "    return TA_wrtIpsiStep, TA_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL, Hip_traj_list_wrt_R, Hip_traj_list_wrt_L):\n",
    "    Hip_wrtIpsiStep = []\n",
    "    Hip_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        Hip_wrtIpsiStep = Hip_traj_list_wrt_R\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        Hip_wrtIpsiStep = -Hip_traj_list_wrt_L+360+180\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        Hip_wrtContraStep = -Hip_traj_list_wrt_R+360+180\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        Hip_wrtContraStep = Hip_traj_list_wrt_L\n",
    "    return Hip_wrtIpsiStep, Hip_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeBA(BA):\n",
    "    BA = [abs(abs(element)-90) for element in BA]\n",
    "    BA = [el for el in BA if el<20]\n",
    "    BA = np.array(BA)\n",
    "    return BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeemptyarray(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high and return to COL 15\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_listwrtR = values_list[i][4]\n",
    "        TA_traj_listwrtL = values_list[i][6]\n",
    "        COM_traj_list = values_list[i][9]\n",
    "        COMX_traj_list = values_list[i][11]\n",
    "        Hip_traj_list_wrt_R = values_list[i][12]\n",
    "        Hip_traj_list_wrt_L = values_list[i][17]\n",
    "        StepAnlge_traj_list = values_list[i][13]\n",
    "        ContraStep_traj_list = values_list[i][14]\n",
    "        Step_x_traj_list = values_list[i][3]\n",
    "        BA_traj_wrtR = values_list[i][16]\n",
    "        cent_dist_traj_wrtR = values_list[i][20]\n",
    "        values_to_append = []\n",
    "        for j, k in zip(np.arange(len(TA_traj_listwrtR)), np.arange(len(TA_traj_listwrtL))):\n",
    "            if len(TA_traj_listwrtR[j]) and len(COM_traj_list[j]):\n",
    "                #Transpose traces beyond 0-360 and exclude traces that are still beyon range\n",
    "                TA_traj_listwrtL_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtL[k])\n",
    "                TA_traj_listwrtR_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtR[j])\n",
    "                Hip_traj_transpose = transpose_TA_ipsi_contra_within0_360_range(Hip_traj_list_wrt_R[j])####\n",
    "                Hip_traj_transpose = transpose_TA_ipsi_contra_within0_360_range(Hip_traj_transpose)####\n",
    "                #divide TA traces based on contra step\n",
    "                TA_wrtIpsiStep, TA_wrtContraStep = decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T)\n",
    "                HA_wrtIpsiStep, HA_wrtContraStep = decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T, \\\n",
    "                                                                                       Hip_traj_list_wrt_R[j], \\\n",
    "                                                                                       Hip_traj_list_wrt_L[k])\n",
    "                #Transpose BA R so that there is no jump to -90\n",
    "                BA_tracesR = transposeBA(BA_traj_wrtR[j])\n",
    "                #Compute angle of tail from top cam\n",
    "                new_alpha = np.unwrap((TA_traj_listwrtR[j]+1800)%(360))\n",
    "\n",
    "                if np.nanmean(new_alpha) > 200:\n",
    "                    new_alpha = abs(new_alpha -360)\n",
    "                else:\n",
    "                    new_alpha = abs(new_alpha)\n",
    "                if len(BA_tracesR) ==250 and all(BA_tracesR<20):\n",
    "                    BA_tracesR_mean = np.nanmean(BA_tracesR[75:175])\n",
    "                else:\n",
    "                    BA_tracesR_mean = []\n",
    "                TA_topcam = new_alpha\n",
    "                TA_topcam_mean = np.nanmean(TA_topcam)\n",
    "                #Assign to value in dict\n",
    "                values_to_append.append([TA_topcam, TA_traj_listwrtR[j], COM_traj_list[j], COMX_traj_list[j], \\\n",
    "                                         Hip_traj_list_wrt_R[j], StepAnlge_traj_list[j],\\\n",
    "                                         Step_x_traj_list[j], StepAnlge_traj_list[j], TA_wrtContraStep, \\\n",
    "                                         TA_wrtIpsiStep, TA_traj_listwrtL[k], ContraStep_traj_list[j], \\\n",
    "                                         Hip_traj_list_wrt_L[k], HA_wrtIpsiStep, HA_wrtContraStep, TA_topcam_mean, \\\n",
    "                                         TA_topcam, BA_tracesR, BA_tracesR_mean, cent_dist_traj_wrtR[j], Hip_traj_transpose])\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def firstNonNan(listfloats):\n",
    "#     i = 0\n",
    "#     for item in listfloats:\n",
    "#         i += 1\n",
    "#         if math.isnan(item) == False:\n",
    "#             return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to compute speed of COM\n",
    "def return_COM_speed(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        #print(values_list[14][-1])\n",
    "\n",
    "        COM_traj_list = values_list[i][-1]# last value in dict with COM empty array excluded\n",
    "        COM_to_append = []\n",
    "        for j in np.arange(len(COM_traj_list)):\n",
    "            COM_traj = COM_traj_list[j][1]\n",
    "            Centroid_DIST_traj_subtract1stelement = COM_traj-COM_traj[0]\n",
    "            Centr_vel = (Centroid_DIST_traj_subtract1stelement[-1])/np.size(COM_traj)\n",
    "            Centr_vel_pixelPersecond = Centr_vel *300 #300 Hz frames\n",
    "            COM_to_append.append(Centr_vel_pixelPersecond)\n",
    "        dict_ridge[key_list[i]].append(COM_to_append)  \n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to compute speed of COM\n",
    "def return_TA_integral_Rstep(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_list = values_list[i][-2]# last value in dict with TA empty array excluded\n",
    "        #print(TA_traj_list)\n",
    "        TA_to_append = []\n",
    "        for j in np.arange(len(TA_traj_list)):\n",
    "            TA_traj = TA_traj_list[j][0]\n",
    "            TA_traj_diff = np.diff(TA_traj)\n",
    "            TA_traj_integral = np.trapz(TA_traj_diff[120:150])\n",
    "            TA_to_append.append(TA_traj_integral)\n",
    "        dict_ridge[key_list[i]].append(TA_to_append)  \n",
    "    return dict_ridge  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_zero_to_dict(dict_ridge):\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    for i in np.arange(len(key_list)):\n",
    "        ridge_array = dict_ridge[key_list[i]][0]\n",
    "        dict_ridge[key_list[i]].append(0)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write script to pre-process and organize all pert trial into python dict\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '15mm', '45mm']\n",
    "\n",
    "dict_preprocessed_all = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    if i < 4:\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "        dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = excludeemptyarray(dict_ridge_el_pert_trial)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array\n",
    "    elif i >3:\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_ridge = append_zero_to_dict(dict_ridge) #to match size with dictionary element in the loop above\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = excludeemptyarray(dict_ridge)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTA_outrange(TA):\n",
    "    if any(i < -30 or i > 250 for i in TA):\n",
    "        TA = []\n",
    "    return TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Mean_STD_forPSTH(array_value_dict):\n",
    "    mean_array = np.nanmean(array_value_dict, axis = 0)\n",
    "    STD_array = stats.sem(array_value_dict, nan_policy='omit')\n",
    "    return mean_array, STD_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### PLOT top camera tail angle and compute mean\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '15mm', '45mm']\n",
    "dict_TA_topcam_mean = defaultdict(dict)\n",
    "\n",
    "\n",
    "for k in np.arange(len(search_key)):    \n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    TA_topcam_mean_list = []\n",
    "    for i in np.arange(len(key_list)):\n",
    "        #print(len(values_list[i]))\n",
    "        TA_traj_wrt_step = values_list[i][-1] #no of last attached array of values\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            plt.plot(TA_traj_wrt_step[j][16]) #no corresponding to top cam TA angle trace\n",
    "            TA_topcam_mean_list.append(TA_traj_wrt_step[j][15]) #no corresponding to top cam TA angle mean\n",
    "    dict_TA_topcam_mean[search_key[k]] = TA_topcam_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute first nonNaN value of array\n",
    "def firstNonNan(listfloats):\n",
    "    for item in listfloats:\n",
    "        if math.isnan(item) == False:\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from edges of ridge\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "threshold_comx = [10, 10, 10, 12, 30]\n",
    "dist_from_edge = [2, 2.5, 4, 5, 22.5]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "dict_cent_dist = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    cent_dist_list = []\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        cent_dist_traj = values_list[i][22]\n",
    "        cent_dist_traj_nonNaN = cent_dist_traj[np.logical_not(numpy.isnan(cent_dist_traj))]\n",
    "        if all(cent_dist_traj_nonNaN < threshold_comx[j]):\n",
    "            #Compute distance from ridge edge, with neg outside of edge\n",
    "            cent_dist_from_edge_traj = -(cent_dist_traj*scaling_pixels[j])+dist_from_edge[j]\n",
    "            plt.plot(cent_dist_from_edge_traj)\n",
    "            cent_dist_list.append(np.nanmean(cent_dist_from_edge_traj))\n",
    "    dict_cent_dist[search_key[j]] = cent_dist_list\n",
    "    #plt.ylim(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot forward velocity and insert value in dict\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "dict_vel = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    vel_list = []\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        comy_traj = values_list[i][21]\n",
    "        comy_traj_nonNaN = comy_traj[np.logical_not(numpy.isnan(comy_traj))]\n",
    "        if all(np.diff(comy_traj_nonNaN)>0) and len(comy_traj_nonNaN):\n",
    "            comy_traj_seg = comy_traj_nonNaN\n",
    "            #Compute first and last nonNan value from CentY and velocity\n",
    "            centY_nonNan_first = comy_traj_seg[0]\n",
    "            centY_nonNan_last = comy_traj_seg[-1]\n",
    "            vel_centY = ((centY_nonNan_last-centY_nonNan_first)*scaling_pixels[j])/(((len(comy_traj_seg))*(1/300))*1000)#scaling m/s\n",
    "            plt.plot(comy_traj_seg)#-centY_nonNan)\n",
    "            #Take avg of 1st and last segments of Centroid trace and compute differences of idx \n",
    "            vel_list.append(vel_centY)\n",
    "    dict_vel[search_key[j]] = vel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot CentroidX and compute average distance from midline\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "scaling_factor = [4, 5, 8, 10, 45] #divide by this number to get relative distance from midline\n",
    "\n",
    "dict_CentX = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    CentX_traj_list = []\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        CentX_traj = (smooth(values_list[i][22], 10))*scaling_pixels[j] #Given that movement of interes is around 30 ms I take a smooth window of 10\n",
    "        CentX_traj_rel = abs(np.diff(CentX_traj/scaling_factor[j]))\n",
    "        CentX_traj_vel_metpersec = CentX_traj_rel*(300)\n",
    "        CentX_traj_nonNaN = CentX_traj[np.logical_not(numpy.isnan(CentX_traj))]\n",
    "        if j <5 and all(CentX_traj_nonNaN<10):\n",
    "            plt.plot(CentX_traj_vel_metpersec)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec))\n",
    "        elif j ==5:\n",
    "            plt.plot(CentX_traj_vel_metpersec)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec))\n",
    "    #plt.ylim(-10, 10)\n",
    "    dict_CentX[search_key[j]] = CentX_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot distance from midline and compute average velocity of distance from midline \n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "scaling_factor = [2, 2.5, 4, 5, 22.5] #divide by this number to get relative distance from midline\n",
    "\n",
    "dict_CentX = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    CentX_traj_list = []\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        CentX_traj = ((smooth(values_list[i][22], 10))*scaling_pixels[j])#Convert to mm\n",
    "        CentX_traj_rel = abs(np.diff(CentX_traj/scaling_factor[j]))\n",
    "        CentX_traj_vel_metpersec = CentX_traj_rel/(1/300) #convert to mm/s\n",
    "        CentX_traj_nonNaN = CentX_traj[np.logical_not(numpy.isnan(CentX_traj))]\n",
    "        if j <5 and all(CentX_traj_nonNaN<10):\n",
    "            plt.plot(CentX_traj_rel)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec))\n",
    "        elif j == 5:\n",
    "            plt.plot(CentX_traj_rel)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec))\n",
    "    #plt.ylim(-10, 30)\n",
    "    dict_CentX[search_key[j]] = CentX_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot CentroidX and compute average velocity of CentroidX (horizontal sway)\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "scaling_factor = [2, 2.5, 4, 5, 22.5] #divide by this number to get relative distance from midline\n",
    "\n",
    "dict_CentX = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    CentX_traj_list = []\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        CentX_traj = (smooth(values_list[i][2], 10))*scaling_pixels[j]#Convert to mm\n",
    "        CentX_traj_rel = np.diff(CentX_traj/scaling_factor[j])\n",
    "        CentX_traj_vel_metpersec = CentX_traj_rel/(1/300) #convert to mm/s\n",
    "        CentX_traj_vel_metpersec_nonNaN = CentX_traj_vel_metpersec[np.logical_not(numpy.isnan(CentX_traj_vel_metpersec))]\n",
    "        if j <4 and all(CentX_traj_vel_metpersec_nonNaN <35) and all(CentX_traj_vel_metpersec_nonNaN >-40):\n",
    "            plt.plot(CentX_traj_vel_metpersec)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec_nonNaN))\n",
    "        elif j == 4:\n",
    "            plt.plot(CentX_traj_vel_metpersec)\n",
    "            CentX_traj_list.append(np.nanmean(CentX_traj_vel_metpersec_nonNaN))\n",
    "    #plt.ylim(-0.5, 0.5)\n",
    "    dict_CentX[search_key[j]] = CentX_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count no of trials mice COM goes outside of the ridge\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']#, '45mm']\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "scaling_factor = [2, 2.5, 4, 5] #divide by this number to get relative distance from midline\n",
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "\n",
    "dict_CentX = defaultdict(dict)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "for j in np.arange(len(search_key)):\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    bla = dict_ridge_all[search_key[j]]\n",
    "    values_list = list(bla.values())\n",
    "    key_list = list(bla.keys())\n",
    "    CentX_traj_list = []\n",
    "    a = 0\n",
    "    for i in np.arange(len(key_list)-1):\n",
    "        CentX_traj = (smooth(values_list[i][22], 10))*scaling_pixels[j] #Given that movement of interes is around 30 ms I take a smooth window of 10\n",
    "        CentX_traj_rel = CentX_traj/scaling_factor[j]\n",
    "        CentX_traj_vel_metpersec = CentX_traj_rel#*(300)\n",
    "        CentX_traj_nonNaN = CentX_traj[np.logical_not(numpy.isnan(CentX_traj))]\n",
    "        if j <5 and all(CentX_traj_nonNaN<6):# and len(CentX_traj_vel_metpersec) == 509:\n",
    "            plt.plot(CentX_traj_vel_metpersec, c = clrs[j], lw=0.3, alpha = 0.8)\n",
    "            count_outCOM = np.where(CentX_traj_vel_metpersec > 1, 1, 0)\n",
    "            sum_count_outCOM = np.sum(count_outCOM)\n",
    "            perc_time_p_outCOM = sum_count_outCOM/500\n",
    "            if sum_count_outCOM>10:\n",
    "                a = a+1\n",
    "#            non_nan_array = CentX_traj_vel_metpersec[~np.isnan(CentX_traj_vel_metpersec)]\n",
    "#             if len(non_nan_array[100:400]) == 300:\n",
    "#                 CentX_traj_list.append(non_nan_array[100:400])\n",
    "#         elif j ==5:\n",
    "#             plt.plot(CentX_traj_vel_metpersec)\n",
    "#             CentX_traj_list.append(CentX_traj_vel_metpersec)\n",
    "    print(a)\n",
    "    plt.ylim(-1, 3)\n",
    "    dict_CentX[search_key[j]] = CentX_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count fwd speed divided by Mouse ID *******************************\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "ridge_half_widths = [2.5, 3, 5, 6]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "\n",
    "dict_perc_time_p_outCOM = defaultdict(dict)\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    vel_list_mouseID = []\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_ridge_all[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        vel_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            comy_traj = values_list[i][21]\n",
    "            comy_traj_nonNaN = comy_traj[np.logical_not(numpy.isnan(comy_traj))]\n",
    "            if all(np.diff(comy_traj_nonNaN)>-0.9) and len(comy_traj_nonNaN):\n",
    "                comy_traj_seg = comy_traj_nonNaN\n",
    "                #Compute first and last nonNan value from CentY and velocity\n",
    "                centY_nonNan_first = comy_traj_seg[0]\n",
    "                centY_nonNan_last = comy_traj_seg[-1]\n",
    "                vel_centY = ((centY_nonNan_last-centY_nonNan_first)*scaling_pixels[j])/(((len(comy_traj_seg))*(1/300))*1000)#scaling m/s\n",
    "                plt.plot(comy_traj_seg)#-centY_nonNan)\n",
    "                #Take avg of 1st and last segments of Centroid trace and compute differences of idx \n",
    "                vel_list.append(vel_centY)\n",
    "#                 print(len(vel_list))\n",
    "        vel_list_mouseID.append(np.nanmean(vel_list))\n",
    "#         print(len(vel_list_mouseID))\n",
    "        dict_perc_time_p_outCOM[search_key[j]] = vel_list_mouseID\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count % of trials mice COM within BoS divided by Mouse ID  *******************************\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "ridge_half_widths = [2.5, 3, 5, 6]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "\n",
    "dict_perc_time_p_outCOM = defaultdict(dict)\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    perc_time_p_outCOM_listMouseID = []\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_ridge_all[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        perc_time_p_outCOM_list = []\n",
    "        a = 0\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            CentX_traj = values_list[i][22] #Given that movement of interes is around 30 ms I take a smooth window of 10\n",
    "            CentX_traj_nonNaN = CentX_traj[np.logical_not(numpy.isnan(CentX_traj))]\n",
    "            if j <4 and all(CentX_traj_nonNaN<6):# and len(CentX_traj_vel_metpersec) == 509:\n",
    "                plt.plot(CentX_traj)#, c = clrs[j])#, lw=0.3, alpha = 0.8)\n",
    "                #Count frames where COM is beyond ridge distance\n",
    "                count_outCOM = np.where(CentX_traj > ridge_half_widths[j], 1, 0)\n",
    "                sum_count_outCOM = np.sum(count_outCOM)\n",
    "#                 print(key_list[i])\n",
    "                perc_time_p_outCOM = sum_count_outCOM/500\n",
    "                perc_time_p_outCOM_list.append(perc_time_p_outCOM)\n",
    "        perc_time_p_outCOM_listMouseID.append(1-np.nanmean(perc_time_p_outCOM_list))\n",
    "    dict_perc_time_p_outCOM[search_key[j]] = perc_time_p_outCOM_listMouseID\n",
    "    #plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_perc_time_p_outCOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add entire trial trace of tail angle from top camera divided by Mouse ID in dictionary\n",
    "def extractTAtopcam(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high and return to COL 15\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_topcam = values_list[i][1]\n",
    "        values_to_append = []\n",
    "        if len(TA_topcam):\n",
    "            #exclude nan\n",
    "            TA_topcam_nonNan = TA_topcam[~np.isnan(TA_topcam)]\n",
    "#             #transpose angle of tail from top cam to 0-360 limit\n",
    "#             TA_topcamT = np.unwrap((TA_topcam_nonNan)%(360))\n",
    "            if np.nanmean(TA_topcam_nonNan) > 250:\n",
    "                TA_topcam_nonNan = abs(TA_topcam_nonNan -360)\n",
    "            else:\n",
    "                TA_topcam_nonNan = abs(TA_topcam_nonNan)\n",
    "            #Assign to value in dict\n",
    "#             if all(TA_topcam_nonNan<110):\n",
    "            values_to_append.append(TA_topcam_nonNan)\n",
    "            plt.plot(values_to_append[0])\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute dict with TAtopcam angle only of non pert trials\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '15mm', '45mm']\n",
    "\n",
    "dict_preprocessed_all_TA_topcam = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    if i < 4:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "        dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extractTAtopcam(dict_ridge_el_pert_trial)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all_TA_topcam[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array\n",
    "    elif i >3:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extractTAtopcam(dict_ridge)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all_TA_topcam[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### PLOT top camera tail angle and compute mean by Mouse ID of entire trial\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "dict_TA_topcam_mean = defaultdict(dict)\n",
    "\n",
    "#dict_TAtopcam = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    mean_list_TA_topcam_MouseID = []\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TA_topcam[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        TA_topcam_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            TA_traj_topcam = values_list[i][-1][0] #no of last attached array of values\n",
    "            if all(TA_traj_topcam<150):\n",
    "                #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "                plt.plot(TA_traj_topcam)\n",
    "                #compute peaks of trace\n",
    "                interval_lowlim = 100\n",
    "                interval_uplim = 400                \n",
    "                peaks_idx, _ = find_peaks(TA_traj_topcam[interval_lowlim:interval_uplim], distance = 50)\n",
    "                peaks_value = TA_traj_topcam[interval_lowlim+peaks_idx]\n",
    "                #print(key_list[i])\n",
    "                plt.plot(peaks_idx+interval_lowlim, peaks_value, 'x')\n",
    "                TA_topcam_mean_list.append(max(peaks_value))#exclude first and last 100ms from mean\n",
    "        mean_list_TA_topcam_MouseID.append(np.nanmean(TA_topcam_mean_list))\n",
    "    dict_TA_topcam_mean[search_key[j]] = mean_list_TA_topcam_MouseID\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract angle btw centroid and tail base from topcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND NOT THIS\n",
    "##Add entire trial trace of angle btw centroid and tail base from top camera divided by Mouse ID in dictionary\n",
    "def extractCent_TailBase(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_topcam = values_list[i][25]#23\n",
    "        bla = values_list[i][22]\n",
    "        values_to_append = []\n",
    "        bla_nonNan = bla[~np.isnan(bla)]        \n",
    "        if len(TA_topcam):# and all(bla_nonNan<150):\n",
    "            #exclude nan\n",
    "            TA_topcam_nonNan = TA_topcam[~np.isnan(TA_topcam)]\n",
    "            values_to_append.append(TA_topcam_nonNan)\n",
    "            #plt.plot(values_to_append[0])\n",
    "            plt.plot(TA_topcam_nonNan)\n",
    "        #plt.ylim(-40,40)\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute dict with angle btw centroid and tail base only of non pert trials\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '15mm', '45mm']\n",
    "\n",
    "dict_preprocessed_all_TailBase = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    if i < 4:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "        dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extractCent_TailBase(dict_ridge_el_pert_trial)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all_TailBase[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array\n",
    "    elif i >3:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "        dict_ridge = dict_ridge_all[search_key[i]]\n",
    "        dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extractCent_TailBase(dict_ridge)#dict_TA_transpose_btw_0_360)\n",
    "        dict_preprocessed_all_TailBase[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amlpit(vector):\n",
    "    ampl = max(vector)# - min(vector)\n",
    "    return ampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_min_max_subtrace(vec):\n",
    "    len_vec = len(vec)\n",
    "    len_vec1 = int(len_vec/3)\n",
    "    len_vec2 = int((len_vec/3)*2)\n",
    "    vec1 = vec[0:len_vec1]\n",
    "    vec2 = vec[len_vec1:len_vec2]\n",
    "    vec3 = vec[len_vec2:len_vec]\n",
    "    vec1_amp = compute_amlpit(vec1)\n",
    "    vec2_amp = compute_amlpit(vec2)\n",
    "    vec3_amp = compute_amlpit(vec3)\n",
    "    mean_vecs = np.nanmean([vec1_amp, vec2_amp, vec3_amp])\n",
    "    return mean_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####  Amplitude of angle btw centroid and tail base by Mouse ID of entire trial\n",
    "MouseID_key = [ 'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "dict_Cent_TailBase_mean = defaultdict(dict)\n",
    "\n",
    "#dict_TAtopcam = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    mean_list_Cent_TailBase_MouseID = []\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        Cent_TailBase_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            Cent_TailBase_traj = values_list[i][-1][0] #no of last attached array of values\n",
    "            bla = values_list[i][22]\n",
    "            bla_nonNan = bla[~np.isnan(bla)]        \n",
    "            if len(Cent_TailBase_traj)>150 and all(bla_nonNan<10):#all(TA_traj_topcam<70) and len(TA_traj_topcam)>250:\n",
    "                Cent_TailBase_traj_abs = abs(Cent_TailBase_traj-180)#exclude first 30 frames, as the tail angle is not visible\n",
    "                plt.plot(Cent_TailBase_traj_abs)#Cent_TailBase_traj_abs)#Cent_TailBase_traj_abs)\n",
    "                Cent_TailBase_amp_means = extract_min_max_subtrace(Cent_TailBase_traj_abs)\n",
    "                Cent_TailBase_mean_list.append(Cent_TailBase_amp_means)\n",
    "        mean_list_Cent_TailBase_MouseID.append(np.nanmean(Cent_TailBase_mean_list))\n",
    "    dict_Cent_TailBase_mean[search_key[j]] = mean_list_Cent_TailBase_MouseID\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## RESCUE THIS\n",
    "# ####  Mean of angle btw centroid and tail base by Mouse ID of entire trial\n",
    "# MouseID_key = ['M62']#'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "# search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "# dict_Cent_TailBase_mean = defaultdict(dict)\n",
    "\n",
    "# #dict_TAtopcam = defaultdict(dict)\n",
    "# for j in np.arange(len(search_key)):\n",
    "#     mean_list_Cent_TailBase_MouseID = []\n",
    "#     fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "#     for k in np.arange(len(MouseID_key)):\n",
    "#         #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "#         dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "#         dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "#         values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "#         key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "#         Cent_TailBase_mean_list = []\n",
    "#         for i in np.arange(len(key_list)-1):\n",
    "#             Cent_TailBase_traj = values_list[i][-1][0] #no of last attached array of values\n",
    "#             bla = values_list[i][22]\n",
    "#             bla_nonNan = bla[~np.isnan(bla)]    \n",
    "#             if len(Cent_TailBase_traj)>150 and all(bla_nonNan<10):\n",
    "#                 Cent_TailBase_traj_abs = abs(Cent_TailBase_traj[30:-1])#exclude first 30 frames, as the tail angle is not visible\n",
    "#                 plt.plot(bla)\n",
    "#                 Cent_TailBase_mean_list.append(np.nanmean(Cent_TailBase_traj_abs))\n",
    "#         mean_list_Cent_TailBase_MouseID.append(np.nanmean(Cent_TailBase_mean_list))\n",
    "#     dict_Cent_TailBase_mean[search_key[j]] = mean_list_Cent_TailBase_MouseID\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND NOT THIS\n",
    "####  Mean of angle btw centroid and tail base by Mouse ID of entire trial\n",
    "MouseID_key = ['M61', 'M62']#'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']#, '45mm']\n",
    "dict_Cent_TailBase_mean = defaultdict(dict)\n",
    "\n",
    "#dict_TAtopcam = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    mean_list_Cent_TailBase_MouseID = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        Cent_TailBase_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            Cent_TailBase_traj = values_list[i][-1][0] #no of last attached array of values\n",
    "            bla = values_list[i][22]\n",
    "            bla_nonNan = bla[~np.isnan(bla)]    \n",
    "            if len(Cent_TailBase_traj)>150 and all(bla_nonNan<10) and all(Cent_TailBase_traj>140) and all(Cent_TailBase_traj<210):\n",
    "                Cent_TailBase_traj_abs = Cent_TailBase_traj[30:-1]#exclude first 30 frames, as the tail angle is not visible\n",
    "                plt.plot(Cent_TailBase_traj_abs)\n",
    "                Cent_TailBase_mean_list.append(np.nanmean(Cent_TailBase_traj_abs))\n",
    "        mean_list_Cent_TailBase_MouseID.append(np.nanmean(Cent_TailBase_mean_list))\n",
    "    dict_Cent_TailBase_mean[search_key[j]] = mean_list_Cent_TailBase_MouseID\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from edges of ridge by mouse ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from edges of ridge\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "threshold_comx = [12, 12, 12, 12, 30]\n",
    "dist_from_edge = [2, 2.5, 4, 5, 22.5]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "dict_cent_dist = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    mean_list_cent_dist_MouseID = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        cent_dist_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            cent_dist_traj = values_list[i][22]\n",
    "            cent_dist_traj_nonNaN = cent_dist_traj[np.logical_not(numpy.isnan(cent_dist_traj))]\n",
    "            if all(cent_dist_traj_nonNaN < threshold_comx[j]):\n",
    "                #Compute distance from ridge edge, with neg outside of edge\n",
    "                cent_dist_from_edge_traj = -(cent_dist_traj*scaling_pixels[j])+dist_from_edge[j]\n",
    "                plt.plot(cent_dist_from_edge_traj)\n",
    "                cent_dist_mean_list.append(np.nanmean(cent_dist_from_edge_traj))\n",
    "        mean_list_cent_dist_MouseID.append(np.nanmean(cent_dist_mean_list))\n",
    "    dict_cent_dist[search_key[j]] = mean_list_cent_dist_MouseID\n",
    "    #plt.ylim(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from midline of ridge by mouse ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from midline of ridge\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "threshold_comx = [12, 12, 12, 12, 30]\n",
    "dist_from_edge = [2, 2.5, 4, 5, 22.5]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "dict_cent_dist = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    mean_list_cent_dist_MouseID = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        cent_dist_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            cent_dist_traj = values_list[i][22]\n",
    "            cent_dist_traj_nonNaN = cent_dist_traj[np.logical_not(numpy.isnan(cent_dist_traj))]\n",
    "            bla = values_list[i][22]\n",
    "            bla_nonNan = bla[~np.isnan(bla)]                \n",
    "            if all(cent_dist_traj_nonNaN < threshold_comx[j]) and all(bla_nonNan<1000):\n",
    "                #Compute distance from ridge edge, with neg outside of edge\n",
    "                cent_dist_from_edge_traj = (cent_dist_traj*scaling_pixels[j])/dist_from_edge[j]\n",
    "                plt.plot(cent_dist_from_edge_traj)\n",
    "                cent_dist_from_edge_amp_means = np.nanmean(cent_dist_from_edge_traj)#extract_min_max_subtrace(cent_dist_from_edge_traj)\n",
    "                cent_dist_mean_list.append(cent_dist_from_edge_amp_means)#np.nanmean(cent_dist_from_edge_traj))\n",
    "        mean_list_cent_dist_MouseID.append(np.nanmean(cent_dist_mean_list))\n",
    "    dict_cent_dist[search_key[j]] = mean_list_cent_dist_MouseID\n",
    "    #plt.ylim(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot and compute distance of Centroid X from midline of ridge ######RE ANALYSIS\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '45mm']\n",
    "threshold_comx = [12, 12, 12, 12, 30]\n",
    "dist_from_edge = [2, 2.5, 4, 5, 22.5]\n",
    "scaling_pixels = [4/5, 5/6, 8/10, 10/12, 45/60]#to convert pixel unit to mm\n",
    "dict_cent_dist = defaultdict(dict)\n",
    "\n",
    "for j in np.arange(len(search_key)):\n",
    "    mean_list_cent_dist_MouseID = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for k in np.arange(len(MouseID_key)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all_TailBase[search_key[j]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "        cent_dist_mean_list = []\n",
    "        for i in np.arange(len(key_list)-1):\n",
    "            cent_dist_traj = values_list[i][22]\n",
    "            cent_dist_traj_nonNaN = cent_dist_traj[np.logical_not(numpy.isnan(cent_dist_traj))]\n",
    "            bla = values_list[i][22]\n",
    "            bla_nonNan = bla[~np.isnan(bla)]                \n",
    "            if all(cent_dist_traj_nonNaN < threshold_comx[j]) and all(bla_nonNan<1000):\n",
    "                #Compute distance from ridge edge, with neg outside of edge\n",
    "                cent_dist_from_edge_traj = np.diff(cent_dist_traj*scaling_pixels[j])\n",
    "                plt.plot(cent_dist_from_edge_traj)\n",
    "                cent_dist_from_edge_amp_means = np.nanstd(cent_dist_from_edge_traj)\n",
    "                cent_dist_mean_list.append(cent_dist_from_edge_amp_means)#np.nanmean(cent_dist_from_edge_traj))\n",
    "        mean_list_cent_dist_MouseID.append(np.nanmean(cent_dist_mean_list))\n",
    "    dict_cent_dist[search_key[j]] = mean_list_cent_dist_MouseID\n",
    "    plt.ylim(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save values into dict\n",
    "\n",
    "data = dict_cent_dist\n",
    "import pandas as pd\n",
    "\n",
    "(pd.DataFrame.from_dict(data=data, orient='index')\n",
    "   .to_csv('dict_perc_time_p_outCOM.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LETS TRY TO GET EVERYTHING IN ONE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add entire trial trace of trace from top camera divided by Mouse ID in dictionary\n",
    "def extract_interest_trace(dict_ridge, idx_id):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for i in np.arange(len(key_list)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        TA_topcam = values_list[i][idx_id]\n",
    "        values_to_append = []\n",
    "        cent_trace = values_list[i][22]\n",
    "        #plt.plot(cent_trace)\n",
    "        cent_trace_nonNan = cent_trace[~np.isnan(cent_trace)]\n",
    "        if len(cent_trace_nonNan):\n",
    "            #print(key_list[i])\n",
    "            cent_trace_nonNan_norm = cent_trace_nonNan-min(cent_trace_nonNan)\n",
    "            #plt.plot(cent_trace_nonNan_norm)\n",
    "            #print(max(cent_trace_nonNan_norm))\n",
    "            if len(TA_topcam) and all(cent_trace_nonNan_norm<10):\n",
    "                values_to_append.append(TA_topcam)\n",
    "                #plt.plot(TA_topcam)\n",
    "            dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add entire trial trace of trace from top camera divided by Mouse ID in dictionary\n",
    "def extract_interest_trace_45mm(dict_ridge, idx_id):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    for i in np.arange(len(key_list)):\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        TA_topcam = values_list[i][idx_id]\n",
    "        values_to_append = []\n",
    "        if len(TA_topcam):\n",
    "            values_to_append.append(TA_topcam)\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_traces_after_QC(dict_ridge):\n",
    "    #exclude traces where ridge trajectory does not look like perturbation trial\n",
    "    list_filenameToExclude = ['M52_Pert_5mm-12142020114124-0000.csv', 'M52_Pert_5mm-12132020144501-0000.csv',\n",
    "                              'M48_NoPert_4mm-12032020123119-0000.csv', 'M49_Pert_8mm-12142020122317-0000.csv', \n",
    "                              'M62_Pert_8mm-12052020172317-0000.csv', 'M62_Pert_8mm-12052020181353-0000.csv',\n",
    "                              'M62_Pert_8mm-12052020181638-0000.csv', 'M62_Pert_10mm-12042020183910-0000.csv',\n",
    "                              'M53_Pert_5mm-12052020143127-0000.csv', 'M53_Pert_8mm-12042020133620-0000.csv',\n",
    "                              'M53_Pert_8mm-12042020145745-0000.csv', 'M53_Pert_4mm-12072020160943-0000.csv',\n",
    "                              'M53_Pert_4mm-12172020150428-0000.csv', 'M54_Pert_8mm-12042020134307-0000.csv',\n",
    "                               'M54_Pert_8mm-12042020134445-0000.csv', 'M49_Pert_8mm-12052020114651-0000.csv',\n",
    "                              'M49_Pert_8mm-12052020114218-0000.csv', 'M49_Pert_10mm-12062020123922-0000.csv',\n",
    "                              'M49_Pert_10mm-12062020112157-0000.csv', 'M54_Pert_8mm-12142020150124-0000.csv',\n",
    "                              'M54_Pert_8mm-12142020150208-0000.csv', 'M54_Pert_8mm-12142020150437-0000.csv',\n",
    "                             'M54_Pert_8mm-12042020143443-0000.csv ', 'M50_Pert_8mm-12142020122848-0000.csv',\n",
    "                              'M58_Pert_5mm-12062020184518-0000.csv', 'M58_Pert_5mm-12062020175820-0000.csv',\n",
    "                              'M58_Pert_10mm-12062020165509-0000.csv', 'M58_Pert_5mm-12062020165541-0000.csv',\n",
    "                               'M58_Pert_5mm-12062020165655-0000.csv', ] \n",
    "\n",
    "    for i in np.arange(len(list_filenameToExclude)):\n",
    "        key_to_be_deleted = list_filenameToExclude[i]\n",
    "        dict_ridge.pop(key_to_be_deleted, None)\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute dict with angle only of non pert trials\n",
    "def extract_non_pert_trials(search_key, idx_id):\n",
    "    dict_preprocessed_all = defaultdict(dict)\n",
    "    for i in np.arange(len(search_key)):\n",
    "        if i < 4:\n",
    "            #fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "            dict_ridge = dict_ridge_all[search_key[i]]\n",
    "            dict_ridge = exclude_traces_after_QC(dict_ridge)\n",
    "            dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "            dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "            dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extract_interest_trace(dict_ridge_el_pert_trial, idx_id)#dict_TA_transpose_btw_0_360)\n",
    "            dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array\n",
    "        elif i >3:\n",
    "            #fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "            dict_ridge = dict_ridge_all[search_key[i]]\n",
    "            dict_ridge = exclude_traces_after_QC(dict_ridge)\n",
    "            dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = extract_interest_trace_45mm(dict_ridge, idx_id)#dict_TA_transpose_btw_0_360)\n",
    "            dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array\n",
    "    return dict_preprocessed_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_rid_jumps(trace, low_tresh, high_thresh):\n",
    "# #     a = np.pad(abs(np.diff(trace)), 1)\n",
    "# #     a = a[1:]\n",
    "#     trace_out_jumps = trace[trace < high_thresh]\n",
    "#     trace_out_jumps = trace_out_jumps[trace_out_jumps > low_tresh]\n",
    "\n",
    "#     return  trace_out_jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amlpit(vector):\n",
    "    ampl = max(vector)# - min(vector)\n",
    "    return ampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_min_max_subtrace(vec):\n",
    "    len_vec = len(vec)\n",
    "    len_vec1 = int(len_vec/3)\n",
    "    len_vec2 = int((len_vec/3)*2)\n",
    "    vec1 = vec[0:len_vec1]\n",
    "    vec2 = vec[len_vec1:len_vec2]\n",
    "    vec3 = vec[len_vec2:len_vec]\n",
    "    vec1_amp = compute_amlpit(vec1)\n",
    "    vec2_amp = compute_amlpit(vec2)\n",
    "    vec3_amp = compute_amlpit(vec3)\n",
    "    mean_vecs = np.nanmean([vec1_amp, vec2_amp, vec3_amp])\n",
    "    return mean_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PLOT top camera tail angle and compute mean by Mouse ID of entire trial\n",
    "def plot_extract_mean(dict_preprocessed_all, search_key, MouseID_key, idx_id, thresh_1, thresh2, inter_1, inter_2, center):\n",
    "    dict_mean = defaultdict(dict)\n",
    "    dict_std = defaultdict(dict)\n",
    "    dict_max = defaultdict(dict)\n",
    "    for j in np.arange(len(search_key)):\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "        mean_list_MouseID = []\n",
    "        std_list_MouseID = []\n",
    "        max_list_MouseID = []\n",
    "        for k in np.arange(len(MouseID_key)):\n",
    "            #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "            dict_ridge_Xwidth = dict_preprocessed_all[search_key[j]]\n",
    "            dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[k] in item[0], dict_ridge_Xwidth.items())) \n",
    "            values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "            key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "            mean_traj_abs_list = []\n",
    "            std_traj_list = []\n",
    "            max_traj_list = []\n",
    "            for i in np.arange(len(key_list)-1):\n",
    "                last_value = values_list[i][-1]\n",
    "                if last_value:# and all(traj_non_NaN<thresh_1) and all(traj_non_NaN>thresh2):\n",
    "                #and np.nanstd(traj_non_NaN)<6:\n",
    "                    #print(key_list[i])\n",
    "                    traj = values_list[i][-1][0] #no of last attached array of values\n",
    "                    #plt.plot(traj)\n",
    "                    traj_interval = traj[inter_1:inter_2]\n",
    "                    traj_non_NaN = traj_interval[~np.isnan(traj_interval)]\n",
    "                    if all(traj_non_NaN<thresh_1) and all(traj_non_NaN>thresh2) \\\n",
    "                    and len(traj_non_NaN)>((len(traj_interval)*2)/3):\n",
    "#                         fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "                        traj_interval_filtered = traj[inter_1:inter_2]\n",
    "                        traj_abs = abs(traj_interval_filtered-center)\n",
    "                        mean_traj_abs = np.nanmean(traj_abs)\n",
    "                        plt.plot(traj_interval_filtered)#, 'r')\n",
    "                        max_trace = extract_min_max_subtrace(traj_abs)\n",
    "#                         print(key_list[i], mean_traj_abs)\n",
    "                        mean_traj_abs_list.append(mean_traj_abs)\n",
    "                        std_traj = np.nanstd(traj_interval_filtered)\n",
    "                        std_traj_list.append(std_traj)\n",
    "                        max_traj_list.append(np.nanmean(max_trace))\n",
    "                        #plt.ylim(100, 250)\n",
    "            mean_list_MouseID.append(np.nanmean(mean_traj_abs_list))\n",
    "            std_list_MouseID.append(np.nanmean(std_traj_list))\n",
    "            max_list_MouseID.append(np.nanmean(max_traj_list))\n",
    "        dict_mean[search_key[j]] = mean_list_MouseID\n",
    "        dict_std[search_key[j]] = std_list_MouseID\n",
    "        dict_max[search_key[j]] = max_list_MouseID\n",
    "    return  dict_mean, dict_std, dict_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']#, '45mm']\n",
    "# 1 is TA topcam, thresh_1 is -200, thresh2 is 200, inter_1 is 100 inter_2 450\n",
    "# 2 is centroidX, thresh_1 is 50, thresh2 is 500, inter_1 is 50 inter_2 450, center is 180\n",
    "# 18 is BodyAxis, dict_no_pert, search_key, MouseID_key, value_idx, 110, 70, 100, 400, 90)\n",
    "# 20 is BodyAxis, values (dict_no_pert, search_key, MouseID_key, value_idx, 110, 70, 100, 400, 90)\n",
    "# 23 is cent tail base angle, (dict_no_pert, search_key, MouseID_key, value_idx, 50, -50, 100, 400, 0) #\n",
    "# 24 is nose cent, values (dict_no_pert, search_key, MouseID_key, value_idx, 200, 160, 100, 400, 180) #\n",
    "# 25 is  cent tail1 tail 2, (dict_no_pert, search_key, MouseID_key, value_idx, 250, 100, 150, 450, 180) #\n",
    "# 26 is tail1 nose angle, thresh_1 is 50, thresh2 is 500, inter_1 is 50 inter_2 450, center is 180\n",
    "# 27 is nose tail angle, (dict_no_pert, search_key, MouseID_key, value_idx, 195, 165, 100, 400, 180)\n",
    "# 28 is noce cent tail angle, \n",
    "value_idx = 25\n",
    "dict_no_pert = extract_non_pert_trials(search_key, value_idx)\n",
    "dict_mean, dict_std, dict_max = plot_extract_mean(dict_no_pert, search_key, MouseID_key, value_idx, \\\n",
    "                                                  250, 100, 150, 450, 180) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save values into dict\n",
    "\n",
    "data = dict_mean\n",
    "import pandas as pd\n",
    "\n",
    "(pd.DataFrame.from_dict(data=data, orient='index')\n",
    "   .to_csv('dict_perc_time.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
