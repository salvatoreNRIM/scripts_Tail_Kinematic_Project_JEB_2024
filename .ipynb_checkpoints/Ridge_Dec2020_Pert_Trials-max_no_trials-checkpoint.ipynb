{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0dae2d1e9583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0macos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import acos, degrees\n",
    "from scipy.signal import find_peaks\n",
    "import os.path\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import entropy\n",
    "import pylab as pl\n",
    "from numpy.fft import fft\n",
    "from scipy import stats\n",
    "import numpy\n",
    "from scipy import signal\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_width = 200\n",
    "#centr_rang = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt(a, b, c):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "    math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getridofAngleJumps(alpha):\n",
    "    alpha_rad = [x*(np.pi)/180 for x in alpha]\n",
    "    alpha_rad = np.array(alpha_rad)\n",
    "    alpha_rad[~np.isnan(alpha_rad)] = np.unwrap(alpha_rad[~np.isnan(alpha_rad)])\n",
    "    alpha_unwrap= np.degrees(alpha_rad)\n",
    "    return alpha_unwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_acausal(x,frequency = 0.300):\n",
    "    #b, a = signal.butter(8, 0.150)\n",
    "    sos = signal.butter(4, frequency, output='sos')\n",
    "    y = signal.sosfiltfilt(sos, x)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=1,window='hanning'):\n",
    "#    \"\"\"smooth the data using a window with requested size.\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract RidgeX trajectory from excel file\n",
    "def RidgeX_excel_to_array_preprocessed(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    RidgeX = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    #take just numeric values\n",
    "    RidgeX=pd.to_numeric(RidgeX.iloc[:,0])\n",
    "\n",
    " \n",
    "    return smooth(RidgeX.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def plot_TailAngle(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.8':'tail3_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.9':'tail4_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.10':'tail4_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.11':'tail4_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.12':'tail5_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.13':'tail5_y',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.14':'tail5_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.15':'tail6_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.16':'tail6_y',  \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.17':'tail6_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.18':'tail7_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.19':'tail7_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.20':'tail7_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.21':'tail8_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.22':'tail8_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.23':'tail8_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_x=pd.to_numeric(df.tail3_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_y=pd.to_numeric(df.tail3_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_lik=pd.to_numeric(df.tail3_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_x=pd.to_numeric(df.tail4_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_y=pd.to_numeric(df.tail4_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_lik=pd.to_numeric(df.tail4_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_x=pd.to_numeric(df.tail5_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_y=pd.to_numeric(df.tail5_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_lik=pd.to_numeric(df.tail5_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_x=pd.to_numeric(df.tail6_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_y=pd.to_numeric(df.tail6_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_lik=pd.to_numeric(df.tail6_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_x=pd.to_numeric(df.tail7_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_y=pd.to_numeric(df.tail7_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_lik=pd.to_numeric(df.tail7_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_x=pd.to_numeric(df.tail8_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_y=pd.to_numeric(df.tail8_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_lik=pd.to_numeric(df.tail8_lik[c-chunk_width:c+chunk_width])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_x.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_y.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail4_x.where((df.tail4_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail4_y.where((df.tail4_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail5_x.where((df.tail5_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail5_y.where((df.tail5_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail6_x.where((df.tail6_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail6_y.where((df.tail6_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail7_x.where((df.tail7_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail7_y.where((df.tail7_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail8_x.where((df.tail8_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail8_y.where((df.tail8_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles1=[]\n",
    "    angles2=[]\n",
    "    angles3=[]\n",
    "    angles4=[]\n",
    "    angles5=[]\n",
    "    angles6=[]\n",
    "    angles7=[]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        #x1,y1=df.tail1_x[i],df.tail1_y[i]\n",
    "        vertical = np.array([df.tail1_x[i],df.tail1_y[i]+10])\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])    \n",
    "        tail3 = np.array([df.tail3_x[i],df.tail3_y[i]])\n",
    "        tail4 = np.array([df.tail4_x[i],df.tail4_y[i]])\n",
    "        tail5 = np.array([df.tail5_x[i],df.tail5_y[i]])    \n",
    "        tail6 = np.array([df.tail6_x[i],df.tail6_y[i]])\n",
    "        tail7 = np.array([df.tail7_x[i],df.tail7_y[i]])\n",
    "        tail8 = np.array([df.tail8_x[i],df.tail8_y[i]])    \n",
    "\n",
    "    #Change below to decide 3 points to determine angle\n",
    "        angle1 = angle3pt(tail2, tail1, vertical)\n",
    "        angle2 = angle3pt(tail3, tail1, vertical)\n",
    "        angle3 = angle3pt(tail4, tail1, vertical)\n",
    "        angle4 = angle3pt(tail5, tail1, vertical)\n",
    "        angle5 = angle3pt(tail6, tail1, vertical)\n",
    "        angle6 = angle3pt(tail7, tail1, vertical)\n",
    "        angle7 = angle3pt(tail8, tail1, vertical)\n",
    "        \n",
    "        #Append\n",
    "        angles1.append(round(angle1,2))\n",
    "        angles2.append(round(angle2,2))\n",
    "        angles3.append(round(angle3,2))\n",
    "        angles4.append(round(angle4,2))\n",
    "        angles5.append(round(angle5,2))\n",
    "        angles6.append(round(angle6,2))\n",
    "        angles7.append(round(angle7,2))\n",
    "\n",
    "    df['Angles1']=angles1\n",
    "    df.head()\n",
    "    df['Angles2']=angles2\n",
    "    df.head()\n",
    "    df['Angles3']=angles3\n",
    "    df.head()\n",
    "    df['Angles4']=angles4\n",
    "    df.head()\n",
    "    df['Angles5']=angles5\n",
    "    df.head()\n",
    "    df['Angles6']=angles6\n",
    "    df.head()\n",
    "    df['Angles7']=angles7\n",
    "    df.head()\n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha1 = df.Angles1\n",
    "    alpha2 = df.Angles2\n",
    "    alpha3 = df.Angles3\n",
    "    alpha4 = df.Angles4\n",
    "    alpha5 = df.Angles5\n",
    "    alpha6 = df.Angles6\n",
    "    alpha7 = df.Angles7\n",
    "\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha1 = smooth(getridofAngleJumps(alpha1))\n",
    "    alpha2 = smooth(getridofAngleJumps(alpha2))\n",
    "    alpha3 = smooth(getridofAngleJumps(alpha3))\n",
    "    alpha4 = smooth(getridofAngleJumps(alpha4))\n",
    "    alpha5 = smooth(getridofAngleJumps(alpha5))\n",
    "    alpha6 = smooth(getridofAngleJumps(alpha6))\n",
    "    alpha7 = smooth(getridofAngleJumps(alpha7))\n",
    "\n",
    "    return alpha1, alpha2, alpha3, alpha4, alpha5, alpha6, alpha7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_PawAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.36':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.37':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.38':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.39':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.40':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.41':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RA_x[i],df.RA_y[i]+10])\n",
    "        RA = np.array([df.RA_x[i],df.RA_y[i]])\n",
    "        RP = np.array([df.RP_x[i],df.RP_y[i]])\n",
    "\n",
    "        angle = angle3pt(RP, RA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to plot Right Paw angle trajectory\n",
    "# def plot_LPAngle(file_path, chunk_width, trial_no):\n",
    "#     #Read csv file tail markers\n",
    "#     df = pd.read_csv(file_path[trial_no])\n",
    "# #    df = pd.read_csv(file_path)\n",
    "\n",
    "#     #Rename marker columns\n",
    "#     df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_200000.9':'LP_x',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.10':'LP_y',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.11':'LP_lik',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.12':'LA_x',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.13':'LA_y',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.14':'LA_lik',\n",
    "                       \n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.24':'RA_x',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.25':'RA_y',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.26':'RA_lik',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.21':'RP_x',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.22':'RP_y',\n",
    "#                           'DLC_resnet50_Ridge_walkMay27shuffle1_200000.23':'RP_lik'}, \n",
    "#                  inplace=True)\n",
    "\n",
    "#     #take just numeric values\n",
    "#     df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "#     df.LA_x=pd.to_numeric(df.LA_x[2:])\n",
    "\n",
    "#     df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "#     df.LA_y=pd.to_numeric(df.LA_y[2:])\n",
    "\n",
    "#     df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "#     df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "#     df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "#     df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    \n",
    "#     df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "#     df.LA_lik=pd.to_numeric(df.LA_lik[2:])\n",
    "#     df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "#     df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "#     #substitute low likelihood points with NaN\n",
    "#     #df.tail1_x[]=np.nan\n",
    "#     lik_thresh = 0.1\n",
    "#     df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "#     df.LA_x.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "#     df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "#     df.LA_y.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "#     df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "#     df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "#     df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "#     df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "#     #extract RP x and LP x\n",
    "#     RP_x =  df.RP_x\n",
    "#     LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #Compute and plot tail angle in panda dataframe as last column\n",
    "#     angles=[]\n",
    "#     for i in range(df.shape[0]):\n",
    "#         vertical = np.array([df.LA_x[i],df.LA_y[i]+10])\n",
    "#         LA = np.array([df.LA_x[i],df.LA_y[i]])\n",
    "#         LP = np.array([df.LP_x[i],df.LP_y[i]])\n",
    "\n",
    "#         angle = angle3pt(LP, LA, vertical)\n",
    "#         #Append\n",
    "#         angles.append(round(angle,2))\n",
    "#     df['Angles']=angles\n",
    "#     df.head()\n",
    "    \n",
    "#     #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "#     #x = CentroidXY.X\n",
    "#     alpha = df.Angles\n",
    "#     #Get alpha value at perturbation time to centre the trace to that value\n",
    "# #    alpha_centred = alpha[tot_peaks]\n",
    "#     #Apply function to get rid of angle jumps\n",
    "#     alpha = getridofAngleJumps(alpha)\n",
    "#     #Apply function to smooth\n",
    "#     alpha = smooth(alpha)\n",
    "# #    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "# #    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "# #    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "# #!    return [TailAngle_traj, alpha]\n",
    "#     return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_HipAngle(file_path, chunk_width, trial_no, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.30':'LH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.31':'LH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.32':'LH_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.33':'RH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.34':'RH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.35':'RH_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.LH_x=pd.to_numeric(df.LH_x[c-chunk_width:c+chunk_width])\n",
    "    df.LH_y=pd.to_numeric(df.LH_y[c-chunk_width:c+chunk_width])\n",
    "    df.RH_x=pd.to_numeric(df.RH_x[c-chunk_width:c+chunk_width])\n",
    "    df.RH_y=pd.to_numeric(df.RH_y[c-chunk_width:c+chunk_width])\n",
    "    df.RH_lik=pd.to_numeric(df.RH_lik[c-chunk_width:c+chunk_width])\n",
    "    df.LH_lik=pd.to_numeric(df.LH_lik[c-chunk_width:c+chunk_width])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.LH_x.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LH_y.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_x.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_y.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    LH_x =  df.LH_x\n",
    "    LH_y =  df.LH_y\n",
    "    RH_x =  df.RH_x    \n",
    "    RH_y =  df.RH_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RH_x[i],df.RH_y[i]+10])\n",
    "        RH = np.array([df.RH_x[i],df.RH_y[i]])\n",
    "        LH = np.array([df.LH_x[i],df.LH_y[i]])\n",
    "\n",
    "        angle = angle3pt(LH, RH, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract centroid X Y trajectory\n",
    "def extract_Centroid(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    CentroidXY = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    CentroidXY.rename(columns={'NaN':'X',\n",
    "                              'NaN.1':'Y'}, \n",
    "                     inplace=True)\n",
    "    #take just numeric values\n",
    "    CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
    "    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "    CentroidX =  CentroidXY.Centroid_x.values\n",
    "    CentroidY =  CentroidXY.Centroid_y.values\n",
    "    CentroidX = [el for el in CentroidX]\n",
    "    CentroidY = [el for el in CentroidY]\n",
    "\n",
    "    return np.array(CentroidX).ravel(), np.array(CentroidY).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delay(a, b):\n",
    "    corr_a_b = np.correlate(a-np.mean(a), b-np.mean(b), mode = 'full')\n",
    "    delay = np.where(corr_a_b == numpy.amin(corr_a_b))# -(np.size(corr_a_b)+1)/2\n",
    "    return delay[0]-(np.size(corr_a_b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_Centroid_edge_dist(file_path, chunk_width, i):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "\n",
    "##Open Centroid file from top camera\n",
    "#CentroidXY = pd.read_csv('C:/Users/Salvo/Desktop/Ridge/DLC_videos/Videos_to_analyzeDLC/Ridge_MiceS20-S24_16thApril/perturbation_8mm_1/8_S22/Centroid.csv')\n",
    "\n",
    "    #Select 1st column csv file\n",
    "    matrix2 = df[df.columns[0]]#.as_matrix()\n",
    "    Centroid1stcol = matrix2.tolist() #file 1st column\n",
    "\n",
    "\n",
    "#    CentroidXY.rename(columns={'NaN':'dist'}, \n",
    "#                     inplace=True)\n",
    "    #take just numeric values\n",
    "    Centroid1stcol = pd.to_numeric(Centroid1stcol)\n",
    "#    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "#    CentroidX =  CentroidXY.Centroid_x\n",
    "#    CentroidY =  CentroidXY.Centroid_y\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width:tot_peaks+centr_rang-chunk_width]#-[CentroidX[tot_peaks]]\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width-100:tot_peaks-100]-[CentroidX[tot_peaks-100]]\n",
    "    return smooth(Centroid1stcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#np.arange(len(file_to_open)-25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i\n",
    "\n",
    "#firstNonNan(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HIST_MI_2_var(a, b):\n",
    "    fig = plt.figure(figsize=(10,14))\n",
    "    ax1 = plt.subplot(311)\n",
    "    ax2 = plt.subplot(312)\n",
    "    hist_centr = ax1.hist(a, density=True, bins=30, color = 'orange')  # `density=False` would make counts\n",
    "    hist_tail = ax2.hist(b, density=True, bins=30, color = 'blue')  # `density=False` would make counts\n",
    "#    ent_cent = entropy(hist_centr[0], base=2)\n",
    "#    ent_tail = entropy(hist_tail[0], base=2)\n",
    "    MI_cent_tail = metrics.mutual_info_score(hist_centr[0], hist_tail[0])\n",
    "    return MI_cent_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_delay_array(var1, var2):\n",
    "    var1 = var1[~np.isnan(var1)] #centroid\n",
    "    var2 = var2[~np.isnan(var2)] #TA\n",
    "    #take the mean out\n",
    "#    var1 = var1-np.mean(var1)\n",
    "#    var2 = var2-np.mean(var2)\n",
    "\n",
    "    corr_a_b = np.correlate(var2, var1, mode = 'full')\n",
    "    norm_corr_a_b = np.correlate(var2/np.std(var2), var1/np.std(var1), mode = 'full')\n",
    "    cc_trace_midpoint = len(norm_corr_a_b)\n",
    "    delay = np.argmax(abs(norm_corr_a_b))-(cc_trace_midpoint/2)+1 #Get the delay of the absolute max peak\n",
    "    max_peak = max(norm_corr_a_b, key=abs)\n",
    "#    max_peak = abs(max(corr_a_b, key=abs))\n",
    "    return delay, max_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(chunk_width, data):\n",
    "    # Number of sample points\n",
    "    N = chunk_width*2\n",
    "    # sample spacing\n",
    "    T = 1/300\n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "    y = data\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0, 1/(2*T), N//2)\n",
    "#    plt.plot(xf, 2/N * np.abs(yf[0:N//2]))\n",
    "#    plt.grid()\n",
    "#    plt.show()\n",
    "    return xf, yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks_extractchunk(x_diff, x, y, z, w, t, threshold_height, chunk_width_step):\n",
    "    peaks, _ = find_peaks(x_diff, height=threshold_height)\n",
    "    out_step = []\n",
    "    out_TA = []\n",
    "    out_HA = []\n",
    "    out_cent = []\n",
    "    out_RstepAng = []\n",
    "\n",
    "    for i in np.arange(len(peaks)):\n",
    "        chunk_trial_step = x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA = y[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_HA = z[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_cent = w[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_RstepAng = t[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        \n",
    "\n",
    "        out_step.append(chunk_trial_step)\n",
    "        out_TA.append(chunk_trial_TA)\n",
    "        out_HA.append(chunk_trial_HA)\n",
    "        out_cent.append(chunk_trial_cent)\n",
    "        #transpose all traces of step angle greater than 360 back to 0\n",
    "        if np.nanmean(chunk_trial_RstepAng) > 250:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng-360)\n",
    "        elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng+360)   \n",
    "        else:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng)\n",
    "\n",
    "\n",
    "    \n",
    "    return out_step, out_TA, out_HA, out_cent, out_RstepAng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as mpl_text\n",
    "\n",
    "class AnyObject(object):\n",
    "    def __init__(self, text, color):\n",
    "        self.my_text = text\n",
    "        self.my_color = color\n",
    "\n",
    "class AnyObjectHandler(object):\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        print(orig_handle)\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        width, height = handlebox.width, handlebox.height\n",
    "        patch = mpl_text.Text(x=0, y=0, text=orig_handle.my_text, color=orig_handle.my_color, verticalalignment=u'baseline', \n",
    "                                horizontalalignment=u'left', multialignment=None, \n",
    "                                fontproperties=None, rotation=45, linespacing=None, \n",
    "                                rotation_mode=None)\n",
    "        handlebox.add_artist(patch)\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def delete_bad_traces_FromList(Traces_List, idx_to_eliminate):\n",
    "    for l in np.arange(len(idx_to_eliminate)):\n",
    "        for i in np.arange(len(Traces_List)):\n",
    "            for j in np.arange(len(Traces_List[i])):\n",
    "                if len(Traces_List[i][j]) == 200:\n",
    "                    if i == idx_to_eliminate[l][0] and j == idx_to_eliminate[l][1]:\n",
    "                        Traces_List[i][j] = [] \n",
    "    return Traces_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def check_trace(trace):\n",
    "#     if np.nanmean(trace) <-50:\n",
    "#         trace = trace + 360\n",
    "# #    if np.nanmean(trace) >400:\n",
    "# #        trace = trace - 360\n",
    "#     return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def check_trace_within_0_to_150(trace):\n",
    "#     if np.nanmean(trace) <-50:\n",
    "#         trace = trace + 360\n",
    "#         if np.nanmean(trace) <-50:\n",
    "#             trace = trace + 360\n",
    "# #    elif np.nanmean(trace[0:60]) >150:\n",
    "# #        trace = []\n",
    "#     else:\n",
    "#         trace = trace\n",
    "#     return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(RidgeX_ExcelList_to_open), len(TA_ExcelList_to_open), len(Centroid_ExcelList_to_open), \\\n",
    "#       len(BodyAxis_ExcelList_to_open))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(arr):\n",
    "#     mask = np.isnan(arr)\n",
    "#     idx = np.where(~mask,np.arange(mask.size),0)\n",
    "#     np.maximum.accumulate(idx, out=idx)\n",
    "#     arr[mask] = arr[idx]\n",
    "    df = pd.DataFrame(data=arr.flatten())\n",
    "    df = df.fillna(value=None, method='backfill', axis=None, limit=70, downcast=None)\n",
    "    arr = df.values\n",
    "#    print(type(arr))\n",
    "    return arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Organize all data into python dict\n",
    "from collections import defaultdict\n",
    "\n",
    "search_key_path = ['*4mm*', '*_5mm*', '*8mm*', '*10mm*', '*10_deg*', '*30_deg*']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '10_deg', '30_deg']\n",
    "\n",
    "dict_ridge_widths = defaultdict(dict)\n",
    "dict_ridge_all = defaultdict(dict)\n",
    "dict_ridge_widths = defaultdict(dict)\n",
    "dict_ridge_all = defaultdict(dict)\n",
    "for j in np.arange(len(search_key_path)):\n",
    "    data_location = \"R://UusisaariU//PROCESSED_DATA_BACKUPS//nRIM_MEMBERS//Salvo//RD_all_cond//RD_all_cond_analyzed//\"\n",
    "    RidgeX_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Ridge_X//*.csv'))\n",
    "    TA_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'side_cam//*//*.csv'))\n",
    "    Centroid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Centroid_XY//*.csv'))\n",
    "    BodyAxis_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis//*.csv'))\n",
    "#    print(RidgeX_ExcelList_to_open)\n",
    "#    dict_ridge = {}\n",
    "    for i in np.arange(len(RidgeX_ExcelList_to_open)): # len(peaks)\n",
    "#        fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "        #Extract arrays\n",
    "        RidgeX_traj = RidgeX_excel_to_array_preprocessed(RidgeX_ExcelList_to_open, chunk_width, i)\n",
    "        BodyAxis_traj = RidgeX_excel_to_array_preprocessed(BodyAxis_ExcelList_to_open, chunk_width, i)\n",
    "        CentroidX_traj, CentroidY_traj = extract_Centroid(Centroid_ExcelList_to_open, chunk_width, i)\n",
    "\n",
    "        #Extract traces of Centroid and Tail Angle around the time frame when the mouse is at the ridge center\n",
    "        a = firstNonNan(CentroidX_traj)\n",
    "        b = round((np.size(CentroidX_traj) - np.count_nonzero(np.isnan(CentroidX_traj)))/2)\n",
    "        c = a + b\n",
    "\n",
    "        #Take tail angle traj after extracting chunk of traj of interest around c\n",
    "        TA1, TA2, TA3, TA4, TA5, TA6, TA7 = plot_TailAngle(TA_ExcelList_to_open, chunk_width, i, c)        \n",
    "        HipAngle_traj = plot_HipAngle(TA_ExcelList_to_open, chunk_width, i, c)\n",
    "        pawangle, RPaw_traj, LPaw_traj = plot_PawAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "\n",
    "        TA1_chunk = fill_nan(TA1[c-chunk_width:c+chunk_width])\n",
    "        TA2_chunk = fill_nan(TA2[c-chunk_width:c+chunk_width])\n",
    "        TA3_chunk = fill_nan(TA3[c-chunk_width:c+chunk_width])\n",
    "        TA4_chunk = fill_nan(TA4[c-chunk_width:c+chunk_width])\n",
    "        TA5_chunk = fill_nan(TA5[c-chunk_width:c+chunk_width])\n",
    "        TA6_chunk = fill_nan(TA6[c-chunk_width:c+chunk_width])\n",
    "        TA7_chunk = fill_nan(TA7[c-chunk_width:c+chunk_width])\n",
    "\n",
    "        RidgeX_traj_chunk = fill_nan(RidgeX_traj[c-chunk_width:c+chunk_width])\n",
    "        HipAngle_traj_chunk = fill_nan(HipAngle_traj[c-chunk_width:c+chunk_width])\n",
    "        RPaw_traj_traj_chunk = RPaw_traj[c-chunk_width:c+chunk_width]\n",
    "        LPaw_traj_traj_chunk = LPaw_traj[c-chunk_width:c+chunk_width]\n",
    "        BodyAxis_traj_chunk = fill_nan(BodyAxis_traj[c-chunk_width:c+chunk_width])\n",
    "\n",
    "        #TailAngle_traj_chunk_corrected = check_trace(TailAngle_traj_chunk)\n",
    "        CentroidX_traj_chunk = fill_nan(CentroidX_traj[c-chunk_width:c+chunk_width])\n",
    "        #print(CentroidX_traj_chunk.ravel())\n",
    "        CentroidY_traj_chunk = fill_nan(CentroidY_traj[c-chunk_width:c+chunk_width])\n",
    "        CentroidX_chunk  = fill_nan(CentroidX_traj[c-chunk_width:c+chunk_width])\n",
    "        CentroidX_chunk_withoutNaN = fill_nan(CentroidX_traj[~np.isnan(CentroidX_traj)]) #drop NaN\n",
    "\n",
    "        #Decide here what variables to plot in the three figures\n",
    "        var1 = np.array(RidgeX_traj_chunk)\n",
    "        var2 = np.array(TA1_chunk)\n",
    "        var3 = np.array(CentroidX_traj_chunk)\n",
    "        var4 = np.array([RPaw_traj_traj_chunk, LPaw_traj_traj_chunk, HipAngle_traj_chunk, BodyAxis_traj_chunk, \\\n",
    "                        CentroidY_traj_chunk, CentroidX_traj_chunk, TA1_chunk, TA2_chunk, TA3_chunk, TA4_chunk, \\\n",
    "                        TA5_chunk, TA6_chunk, TA7_chunk])\n",
    "        var5 = CentroidX_traj_chunk\n",
    "# #        Plot traces\n",
    "#         fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "#         clrs = sns.color_palette(\"viridis\", n_colors=8)\n",
    "#         ax1.plot(smooth(var2, 15), color = clrs[0])\n",
    "#         ax1.plot(smooth(var4[7], 15), color = clrs[1])\n",
    "#         ax1.plot(smooth(var4[8], 15), color = clrs[2])\n",
    "#         ax1.plot(smooth(var4[9], 15), color = clrs[3])\n",
    "#         ax1.plot(smooth(var4[10], 15), color = clrs[4])\n",
    "#         ax1.plot(smooth(var4[11], 15), color = clrs[5])\n",
    "#         ax1.plot(smooth(var4[12], 15), color = clrs[6])\n",
    "#         ax1.plot(smooth(var4[2], 15), color = 'r')\n",
    "#         ax1.set_xlabel('Frame no', fontsize = 16)\n",
    "#         ax1.set_ylabel('Angle (degrees)', fontsize = 16)\n",
    "#         plt.axvline(200,0,360, color = 'k')\n",
    "#         plt.savefig('fig1')\n",
    "        \n",
    "        \n",
    "#         ax1.plot(x2, var4[8], color = 'black')\n",
    "#        ax1.plot(np.arange(len(BodyAxis_traj_chunk)), BodyAxis_traj_chunk, color = 'green')\n",
    "#        ax1.plot(np.arange(len(LPaw_traj_traj_chunk)), LPaw_traj_traj_chunk, color = 'magenta')\n",
    "        key_file_name = os.path.basename(RidgeX_ExcelList_to_open[i])\n",
    "#        ax1.set_title(key_file_name)\n",
    "\n",
    "#         ax1.set_xlabel('Frames (300 Hz)')\n",
    "#         ax1.set_ylabel('Tail Angle Velocity (degrees)')\n",
    "        #Make dict\n",
    "        dict_ridge_widths[search_key[j]][key_file_name] = [var1, var2, var3, var4]\n",
    "\n",
    "        dict_ridge_all['all'][key_file_name] = [var1, var2, var3, var4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSTHwrtRidgePeak_beg = 190\n",
    "PSTHwrtRidgePeak_end = 110\n",
    "beg_inter_PSTH = 45\n",
    "end_inter_PSTH = 60\n",
    "array_lenght = end_inter_PSTH+beg_inter_PSTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_dict_value_ridge_pos(dict_ridge):\n",
    "    #Divide trials based on ridge position. Assign -1 for left tilt, +1 for right and 0 for no tilts. Append to 4th col\n",
    "    #Changed the threshold from 5000 to 10000 bcs M53 detected many no pert trials as pert\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "\n",
    "        ridge_array = dict_ridge[key_list[i]][0]\n",
    "        ridge_array_translated_nonNaN = ridge_array[~np.isnan(ridge_array)]\n",
    "        if len(ridge_array_translated_nonNaN[20:40]):\n",
    "            ridge_array_diff = smooth(np.diff(ridge_array_translated_nonNaN), 10)\n",
    "            ridge_trapz = np.trapz(ridge_array_diff)\n",
    "            if ridge_trapz < -30:\n",
    "                dict_ridge[key_list[i]].append(1)\n",
    "            elif ridge_trapz > 30:\n",
    "                dict_ridge[key_list[i]].append(-1)\n",
    "\n",
    "            else:\n",
    "                dict_ridge[key_list[i]].append(0)    \n",
    "        else:\n",
    "            print('not enough ridge trace')\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_FlippedRidgeTraces(dict_ridge):\n",
    "    ###Flip ridge traces (1st col) if they have left tilt (5th col, -1 value) so to make easier peak detection.\n",
    "    # Assign to column 6th\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        RidgeTraj_classvalue = values_list[i][-1]\n",
    "        RidgeTraj = values_list[i][0]\n",
    "        if RidgeTraj_classvalue == -1:\n",
    "            dict_ridge[key_list[i]].append(-RidgeTraj+250)      \n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(RidgeTraj)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx_trace_below_thresh(trace, thresh, ridge_peak):\n",
    "    #Take trace leftward to the peak\n",
    "    #trace_left = trace[0:100]\n",
    "    new_idx = 0\n",
    "    i = ridge_peak\n",
    "    trace = np.diff(smooth(trace, 20))\n",
    "    #print(trace, thresh, ridge_peak)\n",
    "    while i > 0:\n",
    "        if trace[i] < thresh:\n",
    "            new_idx = i\n",
    "            break\n",
    "        else:\n",
    "            i -= 1\n",
    "    return new_idx-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biggest_peak(y):\n",
    "    # Find peaks\n",
    "    i_peaks, _ = find_peaks(y)\n",
    "\n",
    "    # Find the index from the maximum peak\n",
    "    i_max_peak = i_peaks[np.argmax(y[i_peaks])]\n",
    "\n",
    "    return i_max_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_RidgePeak(dict_ridge):\n",
    "    #Find ridge peak for pert trials (-1, 1 values) and append to 7th column\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        RidgeTraj_flipped = values_list[i][-1]\n",
    "        RidgeTraj_classvalue = values_list[i][-2]\n",
    "        if RidgeTraj_classvalue == 1 or RidgeTraj_classvalue == -1:\n",
    "            ridge_array_nonNaN = RidgeTraj_flipped[~np.isnan(RidgeTraj_flipped)] #it's important to remove NaN for findpeaks function\n",
    "            ridge_array_nonNaN_diff = -smooth(np.diff(ridge_array_nonNaN), 10) #flip sign as I took diff\n",
    "            ridge_tilt_peak_idx = find_biggest_peak(ridge_array_nonNaN_diff)\n",
    "\n",
    "            #Use this for PSTH centered at beg of tilt\n",
    "            dict_ridge[key_list[i]].append(ridge_tilt_peak_idx)            \n",
    "            #Use this for PSTH centered at end of tilt\n",
    "            #dict_ridge[key_list[i]].append(ridge_tilt_peak_idx)\n",
    "            \n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append('No Pert')\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_TAClassifier(dict_ridge):\n",
    "    #Take TA value (2nd col) in pert trials (5th col) before ridge peak value (7th col)\n",
    "    #assign -1 for tail on left, +1 for tail on the right and 0 for tail up to 8th col\n",
    "\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        RidgeTraj_classvalue = values_list[i][-3]\n",
    "#         fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "        if (RidgeTraj_classvalue == 1 or RidgeTraj_classvalue == -1):# and len(values_list[i][-1]):\n",
    "            TailTraj = values_list[i][1]\n",
    "            RidgePeak = values_list[i][-1]\n",
    "            AvgTailPos_before_tilt = np.nanmean(TailTraj[RidgePeak-20:RidgePeak])\n",
    "            if AvgTailPos_before_tilt>180:# and AvgTailPos_before_tilt <400:\n",
    "                dict_ridge[key_list[i]].append(-1)\n",
    "            elif AvgTailPos_before_tilt<180:# and AvgTailPos_before_tilt > -10:\n",
    "                dict_ridge[key_list[i]].append(+1)  \n",
    "            else:\n",
    "                #print(key_list[i], 'No tail position')\n",
    "                dict_ridge[key_list[i]].append(0)\n",
    "\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append('No tail position')\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_TrialClassifier(dict_ridge):\n",
    "    #Take TA classifier (8th col) multiply with Ridge classifier (5th col) and assign result to 9th col\n",
    "    #If value is -1 is controlateral if +1 ipsilateral trial. 0 is undetermined or no pert trials\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        Ridge_classvalue = values_list[i][-4]\n",
    "        TA_classvalue = values_list[i][-1]\n",
    "        dict_ridge[key_list[i]].append(Ridge_classvalue*TA_classvalue)   \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransposeNegBodyAxis(BodyAxis):\n",
    "    if np.nanmean(BodyAxis[chunk_width-50:chunk_width+50])<0:\n",
    "        BodyAxisT = -BodyAxis\n",
    "    else:\n",
    "        BodyAxisT = BodyAxis        \n",
    "    return BodyAxisT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipHA_LPert(HA, RidgeTraj_classvalue):\n",
    "    if RidgeTraj_classvalue == -1:\n",
    "        HAT = (-HA)+270+270\n",
    "    else:\n",
    "        HAT = HA\n",
    "    return HAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipBodyAxis_LPert(BodyAxisT, RidgeTraj_classvalue):\n",
    "    if RidgeTraj_classvalue == -1:\n",
    "        BodyAxis_T_F = (-BodyAxisT)+180\n",
    "    else:\n",
    "        BodyAxis_T_F = BodyAxisT\n",
    "    return BodyAxis_T_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BodyAxis_distanceto90(BodyAxisT_F):\n",
    "    BodyAxisdist = abs(BodyAxisT_F-90)\n",
    "    return BodyAxisdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_FlippedTATraces(dict_ridge):\n",
    "    #Flip TA traces (2nd col) of trials with tail on the left at time of perturbation (8th col) so that in PSTH \n",
    "    #they appear in same direction. Append the new traces in col 10\n",
    "    #Also Flip Steps traces\n",
    "\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_classvalue = values_list[i][-2]\n",
    "        TA_trace = values_list[i][1]\n",
    "        Rstep = values_list[i][3][0]\n",
    "        Lstep = values_list[i][3][1]\n",
    "        #Transform body axis by transposing neg traces and flip L pert traces\n",
    "        RidgeTraj_classvalue = values_list[i][-5] #Ridge L, R or no tilt\n",
    "        HA_trace = values_list[i][3][2]\n",
    "        HAT_trace = flipHA_LPert(HA_trace, RidgeTraj_classvalue)\n",
    "        BodyAxis = values_list[i][3][3]\n",
    "        BodyAxisT = TransposeNegBodyAxis(BodyAxis)\n",
    "        BodyAxisT_F = flipBodyAxis_LPert(BodyAxisT, RidgeTraj_classvalue)\n",
    "        BodyAxisdist = BodyAxisT_F#BodyAxis_distanceto90(BodyAxisT_F)\n",
    "        CentroidY = values_list[i][3][4]\n",
    "        CentroidX = values_list[i][3][5]\n",
    "#         fig = plt.figure()\n",
    "#         plt.plot(TA_trace)\n",
    "#         plt.plot(BodyAxisT_F)\n",
    "        if TA_classvalue == -1:\n",
    "            TA_trace = -(TA_trace-360)\n",
    "            Centroid_trace = -(CentroidX-150)\n",
    "            dict_ridge[key_list[i]].append([TA_trace, -Lstep, -Rstep, BodyAxisdist, HAT_trace, CentroidY, Centroid_trace]) #Flip L and R step and trace\n",
    "#             fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "#             ax1.plot(TA_trace)#, CentroidX_chunk)\n",
    "#             ax1.set_title(key_list[i])\n",
    "        else:\n",
    "            TA_trace = TA_trace\n",
    "            Centroid_trace = CentroidX-125\n",
    "            dict_ridge[key_list[i]].append([TA_trace, Rstep, Lstep, BodyAxisdist, HAT_trace, CentroidY, Centroid_trace])      \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dict_value_TA_and_Ridge_chunkPSTH(dict_ridge):\n",
    "    # Take pert trials (9th col) and based on peak (7th col) extract chunk of flipped Ridge and TA traj (6th and 10th col) \n",
    "    # Assign those traces to col 11 and 12\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        PertTrial_classifier = values_list[i][-2]\n",
    "        Ridge_peak = values_list[i][-4]\n",
    "        Ridge_flipped_trace = values_list[i][-5]\n",
    "        TA_flipped_trace = values_list[i][-1][0]\n",
    "        Rstep = values_list[i][-1][1]\n",
    "        Lstep = values_list[i][-1][2]\n",
    "        BodyAxis_trace = values_list[i][-1][3]\n",
    "        HA_trace = values_list[i][-1][4]\n",
    "        CentroidY = values_list[i][-1][5]\n",
    "        CentroidX = values_list[i][-1][6]\n",
    "\n",
    "        if PertTrial_classifier == 1 or PertTrial_classifier == -1:\n",
    "            Ridge_peak = Ridge_peak\n",
    "            Ridge_chunk = Ridge_flipped_trace[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            TA_chunk = TA_flipped_trace[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            HA_chunk = HA_trace[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            RStep_chunk = Rstep[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            LStep_chunk = Lstep[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            BodyAxis_chunk = BodyAxis_trace[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            CentroidY_chunk = CentroidY[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            Ridge_chunk = Ridge_flipped_trace[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            CentroidX_chunk = CentroidX[Ridge_peak-beg_inter_PSTH:Ridge_peak+end_inter_PSTH]\n",
    "            dict_ridge[key_list[i]].append(Ridge_chunk)  \n",
    "            dict_ridge[key_list[i]].append([TA_chunk, RStep_chunk, LStep_chunk, BodyAxis_chunk, HA_chunk, \\\n",
    "                                           CentroidY_chunk, Ridge_chunk, CentroidX_chunk]) \n",
    "#             fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "            ax1.plot(TA_chunk)#, CentroidX_chunk)\n",
    "#             ax1.set_title(key_list[i])\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(Ridge_flipped_trace)  \n",
    "            dict_ridge[key_list[i]].append([TA_flipped_trace, Rstep, Lstep, BodyAxis_trace, HA_trace, \\\n",
    "                                           CentroidY, Ridge_flipped_trace, CentroidX])  \n",
    "\n",
    "\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipCentroidX_contratrials(CentroidX, PertTrial_classifier):\n",
    "    if PertTrial_classifier == 1:\n",
    "        CentroidX = -CentroidX\n",
    "    elif PertTrial_classifier == -1:\n",
    "        CentroidX = CentroidX\n",
    "    else:\n",
    "        CentroidX = CentroidX\n",
    "    return CentroidX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_highest_peak(peak_idx, trace):\n",
    "    peak_values = trace[peak_idx]\n",
    "    list_peak_values = peak_values.tolist()\n",
    "#    print(list_peak_values)\n",
    "    max_value = max(list_peak_values)\n",
    "    max_idx = list_peak_values.index(max_value)\n",
    "    \n",
    "    return peak_idx[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignSideandTopCamTraces(dict_ridge):\n",
    "    #Take ridgex and Centroid X traces and find peaks and delay between those two, and center PSTH of two traces\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    beg_inter_PSTH = 100\n",
    "    end_inter_PSTH = 150\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    for i in np.arange(len(key_list)):\n",
    "        PertTrial_classifier = values_list[i][-4]\n",
    "        Ridge_flipped_trace = values_list[i][-7]\n",
    "        TA_flipped_trace = values_list[i][-3][0]\n",
    "        Rstep = values_list[i][-3][1]\n",
    "        Lstep = values_list[i][-3][2]\n",
    "        BodyAxis_trace = values_list[i][-3][3]\n",
    "        HA_trace = values_list[i][-3][4]\n",
    "        CentroidY = values_list[i][-3][5]\n",
    "        \n",
    "        #Find peaks CentroidX\n",
    "        CentroidX = values_list[i][-3][6]\n",
    "        CentroidX_flipped = flipCentroidX_contratrials(CentroidX, PertTrial_classifier)\n",
    "        CentroidX_nonNaN = CentroidX_flipped[~np.isnan(CentroidX_flipped)]\n",
    "        Centroid_X_diff_smoothed = np.diff(smooth(CentroidX_nonNaN, 10))\n",
    "        CentroidX_peak_idx, _ = find_peaks(Centroid_X_diff_smoothed, prominence = 0.2)\n",
    "\n",
    "        #Find peaks RidgeX\n",
    "        Ridge_nonNan = Ridge_flipped_trace[~np.isnan(Ridge_flipped_trace)]\n",
    "        Ridge_X_diff_smoothed = np.diff(smooth(Ridge_nonNan, 10))\n",
    "        RidgeX_peak_idx, _ = find_peaks(Ridge_X_diff_smoothed, prominence = 0.2)\n",
    "    \n",
    "        #Use ridge_peak for centering sidecam traces and CentroidX_peak_idx for topcam traces    \n",
    "        if (PertTrial_classifier == 1 or PertTrial_classifier == -1) and len(CentroidX_peak_idx) \\\n",
    "        and len(Ridge_flipped_trace):\n",
    "            #Find peak begin in RidgeX trace and use that as index for side cam traces\n",
    "            RidgeXHighestPeak = choose_highest_peak(RidgeX_peak_idx, Ridge_X_diff_smoothed)\n",
    "            Ridge_peak = RidgeXHighestPeak\n",
    "            pert_beg_idx = find_idx_trace_below_thresh(Ridge_flipped_trace, 0.5, Ridge_peak)\n",
    "            Ridge_chunk = Ridge_flipped_trace[pert_beg_idx-beg_inter_PSTH:pert_beg_idx+end_inter_PSTH]\n",
    "            TA_chunk = TA_flipped_trace[pert_beg_idx-beg_inter_PSTH:pert_beg_idx+end_inter_PSTH]\n",
    "            RStep_chunk = Rstep[pert_beg_idx-beg_inter_PSTH:pert_beg_idx+end_inter_PSTH]\n",
    "            LStep_chunk = Lstep[pert_beg_idx-beg_inter_PSTH:pert_beg_idx+end_inter_PSTH]\n",
    "            HA_chunk = HA_trace[pert_beg_idx-beg_inter_PSTH:pert_beg_idx+end_inter_PSTH]\n",
    "            #Find peak begin in CentroidX trace and use that as index for top cam traces\n",
    "            CentroidXHighestPeak = choose_highest_peak(CentroidX_peak_idx, Centroid_X_diff_smoothed)\n",
    "            CentroidX_peak_idx = CentroidXHighestPeak\n",
    "            pert_beg_idx_topcam = find_idx_trace_below_thresh(CentroidX_flipped, 0.5, CentroidX_peak_idx)\n",
    "            CentroidX_chunk = CentroidX[pert_beg_idx_topcam-beg_inter_PSTH:pert_beg_idx_topcam+end_inter_PSTH]\n",
    "            CentroidY_chunk = CentroidY[pert_beg_idx_topcam-beg_inter_PSTH:pert_beg_idx_topcam+end_inter_PSTH]\n",
    "            BodyAxis_chunk = BodyAxis_trace[pert_beg_idx_topcam-beg_inter_PSTH:pert_beg_idx_topcam+end_inter_PSTH]\n",
    "            \n",
    "            dict_ridge[key_list[i]].append(Ridge_chunk) \n",
    "            dict_ridge[key_list[i]].append([TA_chunk, RStep_chunk, LStep_chunk, BodyAxis_chunk, HA_chunk, \\\n",
    "                                           CentroidY_chunk, Ridge_chunk, CentroidX_chunk])\n",
    "# #            fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "#             plt.plot(CentroidX_chunk)#, CentroidX_chunk)\n",
    "#             plt.plot(Ridge_chunk)#, CentroidX_chunk)\n",
    "\n",
    "# #             plt.plot(TA_chunk)\n",
    "            if len(CentroidX_chunk):\n",
    "                plt.plot(CentroidX_chunk, 'y')\n",
    "#             #plt.plot(np.diff(smooth(Ridge_chunk, 20))*50, 'r')#, CentroidX_chunk)\n",
    "# #             plt.plot(CentroidX_peak_idx, Centroid_X_diff_smoothed[CentroidX_peak_idx], 'x')\n",
    "# #             plt.title(CentroidX_peak_idx)\n",
    "\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(Ridge_flipped_trace)  \n",
    "            dict_ridge[key_list[i]].append([TA_flipped_trace, Rstep, Lstep, BodyAxis_trace, HA_trace, \\\n",
    "                                           CentroidY, Ridge_flipped_trace, CentroidX])  \n",
    "\n",
    "\n",
    "    return dict_ridge    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_traces_after_QC(dict_ridge):\n",
    "    #exclude traces where ridge trajectory does not look like perturbation trial\n",
    "    list_filenameToExclude = ['M53_Pert_4mm-12072020170241-0000.csv', 'M49_Pert_5mm-12142020110359-0000.csv', 'M50_Pert_8mm-12142020122848-0000.csv',#contra trials\n",
    "                              'M54_Pert_4mm-12072020170519-0000.csv', 'M48_Pert_4mm-12042020111831-0000.csv', 'M56_Pert_8mm-12042020135237-0000.csv',\n",
    "                              'M51_RPert_4mm-12032020112338-0000.csv', 'M50_Pert_4mm-12042020101633-0000.csv', 'M56_Pert_8mm-12042020142051-0000.csv',\n",
    "                              'M54_Pert_4mm-12072020170621-0000.csv', 'M51_Pert_4mm-12042020104950-0000.csv', 'M56_Pert_8mm-12042020142126-0000.csv',\n",
    "                              'M56_Pert_4mm-12072020171624-0000.csv', 'M51_Pert_4mm-12042020105106-0000.csv', 'M53_Pert_10mm-12062020152419-0000.csv', \n",
    "                              'M57_Pert_10mm-12062020160614-0000.csv', 'M59_Pert_10mm-12152020182329-0000.csv', 'M60_Pert_10mm-12152020174839-0000.csv', \n",
    "                              'M62_Pert_10mm-12152020184206-0000.csv',\n",
    "                              'M57_Pert_4mm-12072020172105-0000.csv', 'M52_Pert_4mm-12042020102648-0000.csv',\n",
    "                              'M57_Pert_4mm-12072020172240-0000.csv', 'M59_Pert_5mm-12062020180133-0000.csv',\n",
    "                              'M58_Pert_4mm-12172020171736-0000.csv', 'M60_Pert_5mm-12062020181101-0000.csv',\n",
    "                              'M58_Pert_4mm-12172020172239-0000.csv', 'M61_Pert_5mm-12062020181805-0000.csv',\n",
    "                              'M58_Pert_4mm-12172020172348-0000.csv', 'M62_Pert_5mm-12062020182330-0000.csv',\n",
    "                              'M59_Pert_4mm-12172020172433-0000.csv',\n",
    "                              'M59_Pert_4mm-12172020174857-0000.csv',\n",
    "                              'M61_Pert_4mm-12172020175548-0000.csv',\n",
    "                              'M48_Pert_4mm-12132020125937-0000.csv', 'M52_Pert_5mm-12142020114124-0000.csv', #ipsi\n",
    "                              'M53_Pert_8mm-12142020145729-0000.csv', 'M53_Pert_8mm-12042020143250-0000.csv',\n",
    "                              'M49a_Pert_10mm-12152020155834-0000.csv', 'M49a_Pert_10mm-12152020155945-0000.csv', \n",
    "                              'M49a_Pert_10mm-12152020160050-0000.csv', 'M53_Pert_10mm-12062020154548-0000.csv', \n",
    "                              'M55_Pert_10mm-12062020153001-0000.csv', 'M58_Pert_10mm-12152020172956-0000.csv',\n",
    "                              'M54_Pert_10mm-12062020154831-0000.csv', 'M61_Pert_10mm-12152020175056-0000.csv', \n",
    "                              'M58_Pert_10mm-12042020163408-0000.csv', 'M58_Pert_10mm-12042020163610-0000.csv', \n",
    "                              'M58_Pert_10mm-12042020163743-0000.csv', 'M59_Pert_10mm-12042020182350-0000.csv',\n",
    "                              'M61_Pert_10mm-12042020165302-0000.csv',  \n",
    "                              'M53_Pert_8mm-12042020143320-0000.csv', 'M56_Pert_8mm-12042020142337-0000.csv', \n",
    "                              'M57_Pert_8mm-12042020135806-0000.csv', 'M57_Pert_8mm-12042020142413-0000.csv',\n",
    "                              'M57_Pert_8mm-12042020142609-0000.csv', 'M57_Pert_8mm-12042020142639-0000.csv', \n",
    "                              'M57_Pert_8mm-12042020142738-0000.csv', 'M57_Pert_8mm-12042020142812-0000.csv', \n",
    "                              'M60_Pert_8mm-12052020183057-0000.csv',\n",
    "                              'M50_Pert_4mm-12132020121048-0000.csv', 'M48_aPert_4mm-12042020100650-0000.csv',\n",
    "                              'M50_Pert_4mm-12132020121349-0000.csv', 'M50_Pert_4mm-12042020104554-0000.csv',\n",
    "                              'M50_Pert_4mm-12132020121541-0000.csv', 'M50_Pert_4mm-12042020104655-0000.csv',\n",
    "                              'M50_Pert_4mm-12132020121048-0000.csv', 'M52_Pert_4mm-12042020102432-0000.csv',\n",
    "                              'M57_Pert_4mm-12172020153455-0000.csv', 'M58_Pert_5mm-12062020175346-0000.csv',\n",
    "                              'M56_Pert_4mm-12072020171819-0000.csv', 'M60_Pert_5mm-12062020181412-0000.csv',\n",
    "                              'M60_Pert_4mm-12172020175131-0000.csv', 'M58_Pert_4mm-12172020174405-0000.csv',\n",
    "                              'M58_Pert_10mm-12042020163639-0000.csv', 'M58_Pert_10mm-12152020182235-0000.csv',\n",
    "                              'M48_Pert_5mm-12132020140415-0000.csv']\n",
    "\n",
    "    for i in np.arange(len(list_filenameToExclude)):\n",
    "        key_to_be_deleted = list_filenameToExclude[i]\n",
    "        dict_ridge.pop(key_to_be_deleted, None)\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeNaNTATraces(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is mostly NaN\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    a = 0\n",
    "    for i in np.arange(len(key_list)):\n",
    "        Trial_classvalue = values_list[i][-5]\n",
    "        TA_traj = values_list[i][-1][0]#[0:250]\n",
    "        BodyAxis_trace = values_list[i][-1][3]\n",
    "        CentroidX_trace = values_list[i][-1][7]\n",
    "        no_of_nan_TAtraj = list(np.isnan(TA_traj))\n",
    "        count_NaN = no_of_nan_TAtraj.count(1)\n",
    "# #        fig = plt.figure()\n",
    "#         if Trial_classvalue == 1:\n",
    "#             #plt.plot(TA_traj, 'b')\n",
    "#             a = a+1\n",
    "#             print(a)\n",
    "#             plt.plot(BodyAxis_trace, 'r')\n",
    "        if count_NaN>100:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "        elif len(TA_traj) == 0:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "        elif len(CentroidX_trace) == 0:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write script to pre-process and organize all pert trial into python dict for dict with seperate widths\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm', '10_deg', '30_deg']\n",
    "dict_percswings_widths = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    dict_ridge = dict_ridge_widths[search_key[i]]\n",
    "    dict_ridge = assign_dict_value_ridge_pos(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_FlippedRidgeTraces(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_RidgePeak(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TAClassifier(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TrialClassifier(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_FlippedTATraces(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TA_and_Ridge_chunkPSTH(dict_ridge)\n",
    "    dict_percswings_widths[search_key[i]] = dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write script to pre-process and organize all pert trial into python dict\n",
    "\n",
    "search_key = ['all']#, '5mm', '8mm', '10mm']\n",
    "dict_percswings_all = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    dict_ridge = dict_ridge_all[search_key[i]]\n",
    "    dict_ridge = exclude_traces_after_QC(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_ridge_pos(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_FlippedRidgeTraces(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_RidgePeak(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TAClassifier(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TrialClassifier(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_FlippedTATraces(dict_ridge)\n",
    "    dict_ridge = assign_dict_value_TA_and_Ridge_chunkPSTH(dict_ridge)\n",
    "#    dict_ridge = alignSideandTopCamTraces(dict_ridge)\n",
    "    dict_percswings_all[search_key[i]] = excludeNaNTATraces(dict_ridge)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrajArray_from_dict(dict):\n",
    "    data = list(dict.items())\n",
    "    an_array = np.array(data)\n",
    "    return an_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Mean_STD_forPSTH(array_value_dict):\n",
    "    mean_array = np.nanmean(array_value_dict, axis = 0)\n",
    "    STD_array = stats.sem(array_value_dict, nan_policy='omit')\n",
    "    return mean_array, STD_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_quadrant_classifier(TA, no_quad = 6):\n",
    "    lst = np.arange(361)\n",
    "    chunks_list = np.array_split(lst, no_quad)\n",
    "    classifier = []\n",
    "    for i in np.arange(len(chunks_list)):\n",
    "        first_value = chunks_list[i][0]\n",
    "        last_value = chunks_list[i][-1]\n",
    "        if first_value <= TA <= last_value:\n",
    "            classifier = i\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############Figure 4C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECIDE HERE INTERVAL TO PLOT\n",
    "int_beg = 0\n",
    "int_end = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesHighDerivative(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = smooth(values_list[i][-3][0])\n",
    "        TA_diff = np.diff(TA_traj)\n",
    "        #print(TA_diff)\n",
    "        if np.any(TA_diff>100) or np.any(TA_diff<-100):\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesabove180(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is higher than 180 before pert\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][-1][0]#[0:250]\n",
    "        TA_traj_before_pert = TA_traj[0:100]\n",
    "        #BodyAxis = values_list[i][-3][3]\n",
    "        #plt.plot(TA_traj_before_pert)\n",
    "        if np.any(TA_traj>600) or np.any(TA_traj<-70):# or np.any(BodyAxis>150) or np.any(BodyAxis<50):\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsequenceequally(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx_trace_below_thresh(trace, thresh, ridge_peak):\n",
    "    #Take trace leftward to the peak\n",
    "    #trace_left = trace[0:100]\n",
    "    new_idx = 0\n",
    "    i = ridge_peak\n",
    "    trace = np.diff(smooth(trace, 20))\n",
    "    #print(trace, thresh, ridge_peak)\n",
    "    while i > 0:\n",
    "        if trace[i] < thresh:\n",
    "            new_idx = i\n",
    "            break\n",
    "        else:\n",
    "            i -= 1\n",
    "    return new_idx-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_RT(input_array, reference_index, threshold=0):\n",
    "#     \"\"\"\n",
    "#     Subtract each element of the input array from the value at the reference index,\n",
    "#     then extract the index where the resulting time series crosses a threshold.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_array (list or numpy array): The 1D array.\n",
    "#     - reference_index (int): The index to subtract from.\n",
    "#     - threshold (float): The threshold value for identifying the crossing.\n",
    "\n",
    "#     Returns:\n",
    "#     - crossing_index (int): The index where the time series crosses the threshold after the reference index.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Subtract each element from the value at the reference index\n",
    "#     subtracted_time_series = np.array(input_array[reference_index:]) - input_array[reference_index]\n",
    "\n",
    "#     # Find the index where the subtracted time series crosses the threshold\n",
    "#     crossing_index = next(i for i, value in enumerate(subtracted_time_series) if value > threshold)\n",
    "\n",
    "#     # Adjust the index to be relative to the original array\n",
    "#     crossing_index += reference_index\n",
    "\n",
    "#     return crossing_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_RT(input_array, reference_index, threshold=0):\n",
    "    \"\"\"\n",
    "    Subtract each element of the input array from the value at the reference index,\n",
    "    then extract the index where the resulting time series crosses a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - input_array (list or numpy array): The 1D array.\n",
    "    - reference_index (int): The index to subtract from.\n",
    "    - threshold (float): The threshold value for identifying the crossing.\n",
    "\n",
    "    Returns:\n",
    "    - crossing_index (int): The index where the time series crosses the threshold after the reference index.\n",
    "      Returns -1 if no crossing index is found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subtract each element from the value at the reference index\n",
    "    subtracted_time_series = np.array(input_array[reference_index:]) - input_array[reference_index]\n",
    "\n",
    "    try:\n",
    "        # Find the index where the subtracted time series crosses the threshold\n",
    "        crossing_index = next(i for i, value in enumerate(subtracted_time_series) if value > threshold)\n",
    "\n",
    "        # Adjust the index to be relative to the original array\n",
    "        crossing_index += reference_index\n",
    "\n",
    "    except StopIteration:\n",
    "        # If no crossing index is found, return -1\n",
    "        crossing_index = []#-1\n",
    "\n",
    "    return crossing_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak_vel(array):\n",
    "    array_vel = smooth(np.diff(array), 10)\n",
    "    # Find peaks and their indices\n",
    "    idx_peak, _ = find_peaks(array_vel, distance=15)\n",
    "\n",
    "    if len(idx_peak) == 0:\n",
    "        return None, None  # No peaks found\n",
    "\n",
    "    # Find the index of the highest peak\n",
    "    highest_peak_idx = np.argmax(array_vel[idx_peak])\n",
    "\n",
    "    # Get the value of the highest peak using its index\n",
    "    highest_peak_value = array_vel[idx_peak[highest_peak_idx]]\n",
    "\n",
    "    return highest_peak_value, idx_peak[highest_peak_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_append_AngMomTraces(dict_ridge_Xwidth, angmom_lowerinterv, angmom_higherinterv, color_list):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    TA_traj_list = []\n",
    "    TA_peakvel_list = []\n",
    "    idx_maxvel_list = []\n",
    "    HA_traj_list = []\n",
    "    \n",
    "    clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "    values_filename_list = list(dict_ridge_Xwidth.values())\n",
    "    key_filename_list = list(dict_ridge_Xwidth.keys())\n",
    "    for i in np.arange(len(key_filename_list)):\n",
    "            Trial_classvalue = values_filename_list[i][-4]\n",
    "            RidgePert_classvalue = values_filename_list[i][-8]\n",
    "            HA_traj = values_filename_list[i][-1][4]\n",
    "            TA_traj = values_filename_list[i][-1][0]\n",
    "            Ridge_traj = values_filename_list[i][-1][6]\n",
    "            COMYVel_traj = np.diff(values_filename_list[i][-1][5])\n",
    "#            print(key_filename_list[i], TA_traj)#(values_filename_list[i][-5], RidgePert_classvalue, Trial_classvalue))\n",
    "            #UNCOMMENT 1st LINE FOR CONTRA TRIALS or 2nd LINE FOR IPSI TRIALS\n",
    "            #if TA_traj[110]<250:\n",
    "            #and all(TA_traj>-20)and all(TA_traj[150:200]<220):\n",
    "            #IPSI\n",
    "            #if Trial_classvalue ==-1 and len(TA_traj)==70 and all(TA_traj>-150):\n",
    "            #CONTRA\n",
    "            if Trial_classvalue ==1 and len(TA_traj)==array_lenght and all(TA_traj>-20):# and np.nanmean(TA_traj[0:20])>120: #change to 1 for contra and to -1 for ipsi trials\n",
    "#                 smooth_HA = -(smooth(HA_traj, 10))+360 #ipsi\n",
    "                smooth_HA = (smooth(HA_traj, 10))-180 #contra\n",
    "\n",
    "                #Extract HA in right direction\n",
    "                HA_traj = -HA_traj+360\n",
    "                smooth_TA = smooth(TA_traj, 10)\n",
    "#                 print(smooth_TA)\n",
    "                #Extract RT tail\n",
    "                RT_tail = extract_RT(smooth_TA, 5, 0) #input_array, reference_index, threshold=0\n",
    "                print(RT_tail)\n",
    "                #Plot\n",
    "                TA_peakvel, idx_maxvel = find_peak_vel(smooth_TA[0:40])\n",
    "                ax1.plot(smooth_TA)\n",
    "                ax1.plot(RT_tail, smooth_TA[RT_tail], 'x')\n",
    "#                 ax1.set_title(key_filename_list[i])\n",
    "                #ax1.set_ylim(0, 360)\n",
    "\n",
    "                TA_traj_list.append(smooth_TA)#-np.nanmean(TA_traj))\n",
    "                TA_peakvel_list.append(TA_peakvel)\n",
    "                idx_maxvel_list.append(idx_maxvel)\n",
    "                HA_traj_list.append(smooth_HA)#-np.nanmean(TA_traj))\n",
    "\n",
    "                        \n",
    "    return TA_traj_list, TA_peakvel_list, idx_maxvel_list, HA_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, lineopacity, clrs, label_strings):\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            mean_array[i] = mean_array[i]#[int_beg:int_end]#-mean_array[i][100]\n",
    "            x = np.linspace(0, len(mean_array[i]), len(mean_array[i]))#np.linspace(-50, (int_end-int_beg)/0.3, len(mean_array[i]))\n",
    "            ax1.plot(x, mean_array[i], c=clrs, alpha=lineopacity)\n",
    "            ax1.fill_between(x, mean_array[i]-std_array[i][int_beg:int_end], mean_array[i]+std_array[i][int_beg:int_end], \\\n",
    "                            alpha=0.2, facecolor=clrs, label = label_strings)\n",
    "            #ax1.legend(loc=\"upper right\", fontsize = 13, frameon=False)\n",
    "            ax1.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax1.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AngMom_width(TA_traj_list):\n",
    "    mean_TA, std_TA = return_Mean_STD_forPSTH(TA_traj_list)\n",
    "    means = [mean_TA]\n",
    "    stds = [std_TA]\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key\n",
    "Xwidth_keys = ['4mm']#,'4mm', '30_deg']#'5mm', '8mm', '10mm']#, '30_deg']\n",
    "MouseID_key = ['M49', 'M54', 'M59']#'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "#['M48', 'M49', 'M51']#\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "\n",
    "list_std_AngMom = []\n",
    "list_TAtraj_means = []\n",
    "list_TAtraj_stds = []\n",
    "list_HAtraj_means = []\n",
    "list_HAtraj_stds = []\n",
    "mean_TA_peakvel_list = []\n",
    "mean_idxmaxvel_list = []\n",
    "\n",
    "dict_TAmeansStds_byMouseID_Cond = defaultdict(dict)\n",
    "dict_HAmeansStds_byMouseID_Cond = defaultdict(dict)\n",
    "dict_peakvel_idx = defaultdict(dict)\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "    list_TAtraj = []\n",
    "    list_TAtraj_stds = []\n",
    "    list_HAtraj = []\n",
    "    list_HAtraj_stds = []\n",
    "    dict_ridge_Xwidth = dict_percswings_widths[Xwidth_keys[i]]\n",
    "    for m in np.arange(len(MouseID_key)):\n",
    "#         fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[m] in item[0], dict_ridge_Xwidth.items())) \n",
    "        #print(list(dict_ridge_XwidthXmouseID.keys()))\n",
    "        TA_traj_list, TA_peakvel, idx_maxvel, HA_traj_list = \\\n",
    "        plot_and_append_AngMomTraces(dict_ridge_XwidthXmouseID, angmom_lowerinterv[i], \\\n",
    "                                     angmom_higherinterv[i], color_list[i])\n",
    "        #compute mean peakvel and idxpeakvel\n",
    "#         print(TA_peakvel)\n",
    "        mean_TA_peakvel_list.append(np.nanmean(TA_peakvel))\n",
    "        mean_idxmaxvel_list.append(np.nanmean(idx_maxvel))\n",
    "        dict_peakvel_idx = [mean_TA_peakvel_list, mean_idxmaxvel_list]\n",
    "        #compute means+std\n",
    "        means, stds = compute_AngMom_width(TA_traj_list)\n",
    "        means_HA, stds_HA = compute_AngMom_width(HA_traj_list)\n",
    "\n",
    "        list_TAtraj.append(means)\n",
    "        list_TAtraj_stds.append(stds)\n",
    "        list_HAtraj.append(means_HA)\n",
    "        list_HAtraj_stds.append(stds_HA)\n",
    "        dict_TAmeansStds_byMouseID_Cond[MouseID_key[m]][Xwidth_keys[i]] = [means, stds]\n",
    "        dict_HAmeansStds_byMouseID_Cond[MouseID_key[m]][Xwidth_keys[i]] = [means_HA, stds_HA]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returr neg values\n",
    "def neg(lst):\n",
    "    return [x for x in lst if x < 0] or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "label_strings = ['SAL', 'CNO']\n",
    "lineopacity = [1, 1]#\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "#     fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    for j in np.arange(len(Xwidth_keys)):\n",
    "        plot_PSTH_Mean_STD_label_color_pre_assigned(dict_TAmeansStds_byMouseID_Cond[MouseID_key[i]][Xwidth_keys[j]][0], \\\n",
    "                                                    dict_TAmeansStds_byMouseID_Cond[MouseID_key[i]][Xwidth_keys[j]][1], \\\n",
    "                                                    ax1, lineopacity[j], clrs[j], label_strings[j])\n",
    "        plot_PSTH_Mean_STD_label_color_pre_assigned(dict_HAmeansStds_byMouseID_Cond[MouseID_key[i]][Xwidth_keys[j]][0], \\\n",
    "                                                    dict_HAmeansStds_byMouseID_Cond[MouseID_key[i]][Xwidth_keys[j]][1], \\\n",
    "                                                    ax1, lineopacity[j], clrs[j], label_strings[j])\n",
    "        plt.ylim(0, 360)\n",
    "        #ax1.legend(loc=\"lower left\", prop={'size': 12})\n",
    "        ax1.set_xlabel('Time (s)', fontsize=24)\n",
    "        ax1.set_ylabel('Tail angle (degree)', fontsize=24)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=18) \n",
    "        fig.savefig('nopertTA_allMiceallWidth.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute max velocity and peak to max vel for fig 2a3 (July2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def find_peak_vel(array, peak_offset):\n",
    "#     array_vel = array#smooth(np.diff(array), 5)\n",
    "#     x = np.linspace(1, len(array_vel), len(array_vel))\n",
    "    \n",
    "#     #idx\n",
    "#     idx_peak, _ = find_peaks(array_vel, distance = 15)\n",
    "    \n",
    "#     # Find the index from the maximum peak\n",
    "#     i_max_peak = idx_peak[np.argmax(array_vel[idx_peak])]\n",
    "\n",
    "# #     # Find the x value from that index\n",
    "# #     x_max = np.array(x[i_max_peak])\n",
    "\n",
    "#     return array_vel[i_max_peak], i_max_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_peak_vel(array, peak_offset, threshold):\n",
    "#     array_vel = array  # smooth(np.diff(array), 5)\n",
    "#     x = np.linspace(1, len(array_vel), len(array_vel))\n",
    "\n",
    "#     # Find peaks and their indices\n",
    "#     idx_peak, _ = find_peaks(array_vel, distance=15)\n",
    "\n",
    "#     if len(idx_peak) == 0:\n",
    "#         # No peaks found, return None\n",
    "#         return None, None\n",
    "\n",
    "#     # Find the index from the maximum peak\n",
    "#     i_max_peak = idx_peak[np.argmax(array_vel[idx_peak])]\n",
    "\n",
    "#     # Check if the peak value is above the threshold\n",
    "#     if array_vel[i_max_peak] < threshold:\n",
    "#         # Peak value is below the threshold, return None\n",
    "#         return None, None\n",
    "\n",
    "#     # Uncomment the following lines if you also need the x value from the index\n",
    "#     # Find the x value from that index\n",
    "#     # x_max = np.array(x[i_max_peak])\n",
    "#     return array_vel[i_max_peak], i_max_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def find_peak_vel(array, peak_offset, threshold_low, threshold_high):\n",
    "    array_vel = array  # smooth(np.diff(array), 5)\n",
    "    x = np.linspace(1, len(array_vel), len(array_vel))\n",
    "\n",
    "    # Find peaks and their indices\n",
    "    idx_peak, _ = find_peaks(array_vel, distance=15)\n",
    "\n",
    "    if len(idx_peak) == 0:\n",
    "        # No peaks found, return None\n",
    "        return None, None\n",
    "\n",
    "    # Find the index from the maximum peak\n",
    "    i_max_peak = idx_peak[np.argmax(array_vel[idx_peak])]\n",
    "\n",
    "    # Check if the peak value is within the specified thresholds\n",
    "    peak_value = array_vel[i_max_peak]\n",
    "    if peak_value < threshold_low or peak_value > threshold_high:\n",
    "        # Peak value is outside the specified thresholds, return None\n",
    "        return None, None\n",
    "\n",
    "    # Uncomment the following lines if you also need the x value from the index\n",
    "    # Find the x value from that index\n",
    "    # x_max = np.array(x[i_max_peak])\n",
    "\n",
    "    return peak_value, i_max_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_append_AngMomTraces(dict_ridge_Xwidth, angmom_lowerinterv, angmom_higherinterv, color_list):\n",
    "#     fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    TA_traj_list = []\n",
    "    TA_peakvel_list = []\n",
    "    idx_maxvel_list = []\n",
    "\n",
    "    clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "    values_filename_list = list(dict_ridge_Xwidth.values())\n",
    "    key_filename_list = list(dict_ridge_Xwidth.keys())\n",
    "    for i in np.arange(len(key_filename_list)):\n",
    "            Trial_classvalue = values_filename_list[i][-4]\n",
    "            RidgePert_classvalue = values_filename_list[i][-8]\n",
    "            HA_traj = values_filename_list[i][-1][4]\n",
    "            TA_traj = values_filename_list[i][-1][0]\n",
    "            Ridge_traj = values_filename_list[i][-1][6]\n",
    "            COMYVel_traj = np.diff(values_filename_list[i][-1][5])\n",
    "            #Use Trial_classvalue ==-1 for ipsi and Trial_classvalue ==1  for contra\n",
    "#             if Trial_classvalue ==1 and len(TA_traj)==array_lenght and np.nanmean(TA_traj[0:20])>160: #change to 1 for contra and to -1 for ipsi trials, range [20:60]\n",
    "            if Trial_classvalue ==-1 and len(TA_traj)==array_lenght and np.nanmean(TA_traj[0:20])>160: #change to 1 for contra and to -1 for ipsi trials [20:50]\n",
    "\n",
    "                #Use this for Hips peak vel (keep minus sign for hips, for both ipsi and contra trials)\n",
    "                TA_vel_traj = np.diff(smooth(-HA_traj, 10))\n",
    "\n",
    "#                 #Use this for TA peak vel (use plus sign for ipsi trial, and minus sign for contra trials)\n",
    "#                 TA_vel_traj = np.diff(smooth(TA_traj, 10))\n",
    "\n",
    "                peak_offset = 20+10 #20 for tail, 20+10 for hips\n",
    "                threshold_peak_low = 2.5\n",
    "                threshold_peak_high = 10\n",
    "                TA_peakvel, idx_maxvel = find_peak_vel(TA_vel_traj[peak_offset:45], peak_offset, threshold_peak_low, \\\n",
    "                                                      threshold_peak_high)\n",
    "                if idx_maxvel:\n",
    "                    ax1.plot(TA_vel_traj)\n",
    "                    ax1.plot(idx_maxvel+peak_offset, TA_vel_traj[idx_maxvel+peak_offset], 'x')\n",
    "                    ax1.set_ylim(-15, 15)\n",
    "                    \n",
    "                    TA_traj_list.append(TA_vel_traj)#-np.nanmean(TA_traj))\n",
    "                    TA_peakvel_list.append(TA_peakvel)\n",
    "                    idx_maxvel_list.append(idx_maxvel)\n",
    "\n",
    "                        \n",
    "    return TA_traj_list, TA_peakvel_list, idx_maxvel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, lineopacity, clrs, label_strings):\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            mean_array[i] = mean_array[i][int_beg:int_end]#-mean_array[i][100]\n",
    "            x = np.linspace(-50, (int_end-int_beg)/0.3, len(mean_array[i]))\n",
    "            ax1.plot(x, mean_array[i], c=clrs, alpha=lineopacity)\n",
    "            ax1.fill_between(x, mean_array[i]-std_array[i][int_beg:int_end], mean_array[i]+std_array[i][int_beg:int_end], \\\n",
    "                            alpha=0.2, facecolor=clrs, label = label_strings)\n",
    "            #ax1.legend(loc=\"upper right\", fontsize = 13, frameon=False)\n",
    "            ax1.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax1.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "#             ax.axvline(57/0.3,0,360, color = 'red')\n",
    "#             ax.axvline(73/0.3,0,360, color = 'red')\n",
    "#             ax.axvline(85/0.3,0,360, color = 'red')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AngMom_width(TA_traj_list):\n",
    "    mean_TA, std_TA = return_Mean_STD_forPSTH(TA_traj_list)\n",
    "    means = [mean_TA]\n",
    "    stds = [std_TA]\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_arrays(arrays_list):\n",
    "    return [item for array in arrays_list for item in array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key. Output is dict_TAmeansStds_byMouseID_Cond with all time to peak and peak velocity for all widths trials\n",
    "Xwidth_keys = ['4mm', '5mm', '8mm', '10mm']#,'4mm', '30_deg']#'5mm', '8mm', '10mm']#, '30_deg']\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "#['M48', 'M49', 'M51']\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "\n",
    "list_std_AngMom = []\n",
    "list_TAtraj_means = []\n",
    "list_TAtraj_stds = []\n",
    "mean_TA_peakvel_list = []\n",
    "mean_idxmaxvel_list = []\n",
    "\n",
    "dict_TAmeansStds_byMouseID_Cond = defaultdict(dict)\n",
    "dict_peakvel_idx = defaultdict(dict)\n",
    "\n",
    "\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "#     mean_TA_peakvel_list = []\n",
    "#     mean_idxmaxvel_list = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    dict_ridge_Xwidth = dict_percswings_widths[Xwidth_keys[i]]\n",
    "    for m in np.arange(len(MouseID_key)):\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[m] in item[0], dict_ridge_Xwidth.items())) \n",
    "        #print(list(dict_ridge_XwidthXmouseID.keys()))\n",
    "        TA_traj_list, TA_peakvel, idx_maxvel = \\\n",
    "        plot_and_append_AngMomTraces(dict_ridge_XwidthXmouseID, angmom_lowerinterv[i], \\\n",
    "                                     angmom_higherinterv[i], color_list[i])\n",
    "        #compute mean peakvel and idxpeakvel\n",
    "        mean_TA_peakvel_list.append(TA_peakvel)\n",
    "        mean_idxmaxvel_list.append(idx_maxvel)\n",
    "#         dict_peakvel_idx = [mean_TA_peakvel_list, mean_idxmaxvel_list]\n",
    "#         #compute means+std\n",
    "#         means, stds = compute_AngMom_width(TA_traj_list)\n",
    "#         list_TAtraj.append(means)\n",
    "#         list_TAtraj_stds.append(stds)\n",
    "dict_TAmeansStds_byMouseID_Cond[Xwidth_keys[i]] = [flatten_list_of_arrays(mean_TA_peakvel_list), \\\n",
    "                                                       flatten_list_of_arrays(mean_idxmaxvel_list)]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_TAmeansStds_byMouseID_Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(data, bin_size_method='auto'):\n",
    "    num_sublists = len(data)\n",
    "    fig, axs = plt.subplots(1, num_sublists, figsize=(15, 8 * num_sublists))\n",
    "    axs = axs if num_sublists > 1 else [axs]  # Ensure axs is always iterable\n",
    "\n",
    "    for (label, sublist), ax in zip(data.items(), axs):\n",
    "        values = sublist[1]  # Extract the values from the sublist (change to 0 for peak vel and 1 for time to peak)\n",
    "\n",
    "        if bin_size_method == 'auto':\n",
    "            # Automatically calculate the bin size using Freedman-Diaconis rule\n",
    "            bin_size = 2 * (np.percentile(values, 75) - np.percentile(values, 25)) / (len(values) ** (1/3))\n",
    "        elif bin_size_method == 'sturges':\n",
    "            # Use Sturges' formula to determine the number of bins\n",
    "            num_bins = int(np.ceil(np.log2(len(values) + 1)))\n",
    "            bin_size = (max(values) - min(values)) / num_bins\n",
    "        else:\n",
    "            # Default to 'auto' if an unsupported method is specified\n",
    "            bin_size = 1.0\n",
    "\n",
    "        # Create a separate subplot for each sublist\n",
    "        ax.hist(values, bins=np.arange(min(values), max(values) + bin_size, bin_size), edgecolor='k')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'Histogram of Values - {label}')\n",
    "        ax.grid(axis='y', alpha=0.75)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_histogram(dict_TAmeansStds_byMouseID_Cond, bin_size_method='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dict_TAmeansStds_byMouseID_Cond, bin_size_method='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dict_TAmeansStds_byMouseID_Cond, bin_size_method='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  Compute acceleration comparing diff withs early phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_append_AngMomTraces(dict_ridge_Xwidth, angmom_lowerinterv, angmom_higherinterv, color_list):\n",
    "#     fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    TA_traj_list = []\n",
    "    TA_peakacc_list = []\n",
    "    idx_maxvel_list = []\n",
    "\n",
    "    clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "    values_filename_list = list(dict_ridge_Xwidth.values())\n",
    "    key_filename_list = list(dict_ridge_Xwidth.keys())\n",
    "    for i in np.arange(len(key_filename_list)):\n",
    "            Trial_classvalue = values_filename_list[i][-4]\n",
    "            RidgePert_classvalue = values_filename_list[i][-8]\n",
    "            HA_traj = values_filename_list[i][-1][4]\n",
    "            TA_traj = values_filename_list[i][-1][0]\n",
    "            Ridge_traj = values_filename_list[i][-1][6]\n",
    "            COMYVel_traj = np.diff(values_filename_list[i][-1][5])\n",
    "            #Use Trial_classvalue ==-1 for ipsi and Trial_classvalue ==1  for contra\n",
    "#             if Trial_classvalue ==1 and len(TA_traj)==array_lenght and np.nanmean(TA_traj[0:20])>160: #change to 1 for contra and to -1 for ipsi trials, range [20:60]\n",
    "            if Trial_classvalue ==-1 and len(TA_traj)==array_lenght:# and np.nanmean(TA_traj[0:20])>0: #change to 1 for contra and to -1 for ipsi trials [20:50]\n",
    "\n",
    "                \n",
    "                \n",
    "#                 #Use this for Hips peak vel (keep minus sign for hips, for both ipsi and contra trials)\n",
    "#                 TA_vel_traj = np.diff(smooth(-HA_traj, 10))\n",
    "\n",
    "                #Use this for TA peak vel (use plus sign for ipsi trial, and minus sign for contra trials)\n",
    "                TA_vel_traj = np.diff(smooth(TA_traj, 10))\n",
    "\n",
    "                peak_offset = 20 #20 for tail, 20+10 for hips\n",
    "                threshold_peak_low = 2.5\n",
    "                threshold_peak_high = 10\n",
    "                TA_peakvel, idx_maxvel = find_peak_vel(TA_vel_traj[peak_offset:35], peak_offset, threshold_peak_low, \\\n",
    "                                                      threshold_peak_high)\n",
    "\n",
    "                if idx_maxvel:\n",
    "                    #Compute acceleration\n",
    "                    TA_acc = TA_peakvel/idx_maxvel\n",
    "                    \n",
    "                    ax1.plot(TA_vel_traj)\n",
    "                    ax1.plot(idx_maxvel+peak_offset, TA_vel_traj[idx_maxvel+peak_offset], 'x')\n",
    "                    ax1.set_ylim(-15, 15)\n",
    "                    \n",
    "                    TA_traj_list.append(TA_vel_traj)#-np.nanmean(TA_traj))\n",
    "                    TA_peakacc_list.append(TA_acc)#TA_peakvel)\n",
    "                    idx_maxvel_list.append(idx_maxvel)\n",
    "\n",
    "                        \n",
    "    return TA_traj_list, TA_peakacc_list, idx_maxvel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key. Output is dict_TAmeansStds_byMouseID_Cond with all time to peak and peak velocity for all widths trials\n",
    "Xwidth_keys = ['4mm']#, '5mm', '8mm', '10mm']#,'4mm', '30_deg']#'5mm', '8mm', '10mm']#, '30_deg']\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "#['M48', 'M49', 'M51']\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "\n",
    "list_std_AngMom = []\n",
    "list_TAtraj_means = []\n",
    "list_TAtraj_stds = []\n",
    "mean_TA_peakacc_list = []\n",
    "mean_idxmaxvel_list = []\n",
    "\n",
    "dict_TAmeansStds_byMouseID_Cond = defaultdict(dict)\n",
    "dict_peakvel_idx = defaultdict(dict)\n",
    "\n",
    "\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "#     mean_TA_peakvel_list = []\n",
    "#     mean_idxmaxvel_list = []\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    dict_ridge_Xwidth = dict_percswings_widths[Xwidth_keys[i]]\n",
    "    for m in np.arange(len(MouseID_key)):\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[m] in item[0], dict_ridge_Xwidth.items())) \n",
    "        #print(list(dict_ridge_XwidthXmouseID.keys()))\n",
    "        TA_traj_list, TA_peakacc, idx_maxvel = \\\n",
    "        plot_and_append_AngMomTraces(dict_ridge_XwidthXmouseID, angmom_lowerinterv[i], \\\n",
    "                                     angmom_higherinterv[i], color_list[i])\n",
    "        #compute mean peakvel and idxpeakvel\n",
    "        mean_TA_peakacc_list.append(TA_peakacc)\n",
    "#         mean_idxmaxvel_list.append(idx_maxvel)\n",
    "        \n",
    "#         dict_peakvel_idx = [mean_TA_peakvel_list, mean_idxmaxvel_list]\n",
    "#         #compute means+std\n",
    "#         means, stds = compute_AngMom_width(TA_traj_list)\n",
    "#         list_TAtraj.append(means)\n",
    "#         list_TAtraj_stds.append(stds)\n",
    "dict_TAmeansStds_byMouseID_Cond[Xwidth_keys[i]] = [flatten_list_of_arrays(mean_TA_peakacc_list)]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_TAmeansStds_byMouseID_Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(figsize=(12, 8))\n",
    "# clrs = sns.color_palette(\"husl\", 8)\n",
    "# #fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "# lineopacity = [0.1, 0.5, 1, 1]\n",
    "\n",
    "# legend_id = ['pert 10 deg', 'pert 20 deg', 'pert 30 deg']\n",
    "# for i in np.arange(len(list_means_AngMom)):\n",
    "#     plot_PSTH_Mean_STD_label_color_pre_assigned(list_means_AngMom[i], list_std_AngMom[i], ax, lineopacity[i], legend_id[i])\n",
    "#     print(np.trapz(abs(list_means_AngMom[i][1])))\n",
    "#     ax.set_xlabel('Time (ms)', fontsize=18)\n",
    "#     ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "# plt.savefig('out_bla.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save values into dict\n",
    "\n",
    "# data = dict_TA_AngMom_conditions\n",
    "# import pandas as pd\n",
    "\n",
    "# (pd.DataFrame.from_dict(data=data, orient='index')\n",
    "#    .to_csv('dict_file_TA_tc.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Plot COMY velocity during perturbation for 10-20-30 deg tilts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECIDE HERE INTERVAL TO PLOT\n",
    "int_beg = [75, 75, 75]\n",
    "int_end = [220, 220, 220] #13 is delay interval between end of 10 vs 20 deg, and 9 is delay btw 10vs30 deg tilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_pos_value(l):\n",
    "    min_pos = min([i for i in l if i > 0])\n",
    "    return min_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNo_valuesBelowThresh(l, t):\n",
    "    n = np.count_nonzero(l < t)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_append_COMYVel(dict_ridge_Xwidth, angmom_lowerinterv, angmom_higherinterv, color_list):\n",
    "    search_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    HA_traj_list = []\n",
    "    TA_traj_list = []\n",
    "    HA_traj_list_AngMom = []\n",
    "    TA_traj_list_AngMom = []\n",
    "    Ridge_traj_list = []\n",
    "    TA_cum_angmom_list = []\n",
    "    COMYVel_traj_list = []\n",
    "    v_ratio_list = []\n",
    "    clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "\n",
    "    for i in np.arange(len(search_key)):\n",
    "        res = dict(filter(lambda item: search_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    #     res = excludeTATracesHighDerivative(res)\n",
    "    #    res = excludeTATracesabove180(res)\n",
    "        values_filename_list = list(res.values())\n",
    "        key_filename_list = list(res.keys())\n",
    "        for i in np.arange(len(key_filename_list)):\n",
    "                Trial_classvalue = values_filename_list[i][-4]\n",
    "                if Trial_classvalue ==1: #change to 1 for ips and to -1 for contra trials\n",
    "                    RidgePert_classvalue = values_filename_list[i][-10]\n",
    "                    HA_traj = smooth_acausal(values_filename_list[i][-1][4])\n",
    "                    TA_traj = smooth_acausal(values_filename_list[i][-1][0])\n",
    "                    Ridge_traj = smooth_acausal(values_filename_list[i][-1][6])#/5\n",
    "                    COMYVel_traj = smooth_acausal((values_filename_list[i][-1][5]))\n",
    "                    #UNCOMMENT 1st LINE FOR CONTRA TRIALS or 2nd LINE FOR IPSI TRIALS\n",
    "                    if len(TA_traj) == 250 and len(HA_traj) == 250 and all(TA_traj<410) \\\n",
    "                    and all(TA_traj[150:200]>180) and TA_traj[110]<250:\n",
    "                        x = np.linspace(0, 250/300, 250)\n",
    "                        COMYVel_traj = smooth(np.diff(COMYVel_traj), 10)\n",
    "                        plt.plot(COMYVel_traj,color = clrs[0], lw=1, alpha = 0.1)\n",
    "                        COMYVel_traj_list.append(COMYVel_traj)\n",
    "                        #calculate mean of initial velocity and append to list\n",
    "                        v_0 = np.nanmean(COMYVel_traj[0:50])\n",
    "                        #calculate lowest speed\n",
    "                        lowest_speed = find_min_pos_value(COMYVel_traj)\n",
    "                        #calculate time spent at <0.01 m/s speed (freezing at BMC biol 2020)\n",
    "                        No_values_below_speed = (countNo_valuesBelowThresh(COMYVel_traj, 0.041))* 0.003#0.01/0.24(conversion pixel factor)\n",
    "                        Time_spent_below_thresh = No_values_below_speed* 0.003\n",
    "                        print(No_values_below_speed)\n",
    "                        #calculate ratio and append to list\n",
    "                        v_ratio = lowest_speed/v_0\n",
    "                        v_ratio_list.append(v_ratio)\n",
    "\n",
    "    return COMYVel_traj_list, v_ratio_list                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AngMom_width(TA_traj_list):#, Ridge_traj_list):#HA_traj_list, Ridge_traj_list):\n",
    "    mean_TA, std_TA = return_Mean_STD_forPSTH(TA_traj_list)\n",
    "\n",
    "    mean_TA = (mean_TA)\n",
    "\n",
    "    means = [mean_TA]\n",
    "    stds = [std_TA]\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key\n",
    "Xwidth_keys = ['10_deg','4mm', '30_deg']#'5mm', '8mm', '10mm']#, '30_deg']\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "list_means_AngMom = []\n",
    "list_std_AngMom = []\n",
    "list_TA_AngMom_conditions = []\n",
    "list_HA_AngMom_conditions = []\n",
    "dict_TA_AngMom_conditions = defaultdict(dict)\n",
    "\n",
    "\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "    COMvel_list, v_ratio = \\\n",
    "    plot_and_append_COMYVel(dict_percswings_widths[Xwidth_keys[i]], angmom_lowerinterv[i], \\\n",
    "                                 angmom_higherinterv[i], color_list[i])\n",
    "    #take ratio of initial velocoty by final velocity\n",
    "    #speed_dec_norm = v_0/low_speed#/v_0\n",
    "    print(v_ratio)#, low_speed)\n",
    "    #compute means+stds\n",
    "    means, stds = compute_AngMom_width(COMvel_list)#, Ridge_traj_list)#HA_traj_list, Ridge_traj_list)\n",
    "    list_means_AngMom.append(means)\n",
    "    list_std_AngMom.append(stds)\n",
    "\n",
    "    \n",
    "clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "mean_pert_traces = np.nanmean(TA_traj_list, axis = 0)\n",
    "plt.xlabel('Frame number (FR = 300 Hz)')\n",
    "plt.ylabel('Tail Angle (degrees))')\n",
    "plt.ylim(-6,4)\n",
    "# plt.xlim(100,170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, lineopacity, legend_id, b1, b2):\n",
    "    #clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    label_strings = ['Tail', 'Ridge', 'Hip', 'Ridge']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "    clr_id = [0,2]\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        #boundaries of tilt delay for different durations b1, and b2\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            mean_array[i] = mean_array[i][b1:b2]#-mean_array[i][100]\n",
    "            x = np.linspace(-50, (b2-b1)/0.3, len(mean_array[i]))\n",
    "            ax.plot(x, mean_array[i], c=clrs[clr_id[i]], label = legend_id[i], alpha=lineopacity)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i][b1:b2], mean_array[i]+std_array[i][b1:b2], \\\n",
    "                            alpha=lineopacity, facecolor=clrs[clr_id[i]])\n",
    "            ax.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "#             ax.axvline(50,0,360, color = 'red')\n",
    "#             ax.axvline(65,0,360, color = 'red')\n",
    "#             ax.axvline(75,0,360, color = 'red')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_beg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = 'k'\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "lineopacity = [0.1, 0.3, 0.7, 1]\n",
    "\n",
    "legend_id = ['pert 10 deg', 'pert 20 deg', 'pert 30 deg']\n",
    "for i in np.arange(len(list_means_AngMom)):\n",
    "    plot_PSTH_Mean_STD_label_color_pre_assigned(list_means_AngMom[i], list_std_AngMom[i], ax, lineopacity[i], legend_id[i], \\\n",
    "                                                int_beg[i], int_end[i])\n",
    "    ax.set_xlabel('Time (ms)', fontsize=18)\n",
    "    ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "plt.savefig('out_bla.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Plot data figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECIDE HERE INTERVAL TO PLOT\n",
    "int_beg = 90\n",
    "int_end = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AngMom_width(TA_traj_list, HA_traj_list):#HA_traj_list, Ridge_traj_list):\n",
    "    mean_TA, std_TA = return_Mean_STD_forPSTH(TA_traj_list)\n",
    "    mean_HA, std_HA = return_Mean_STD_forPSTH(HA_traj_list)\n",
    "    #mean_Ridge, std_Ridge = return_Mean_STD_forPSTH(Ridge_traj_list)\n",
    "\n",
    "    mean_TA = (mean_TA*8.15)\n",
    "    mean_HA=mean_HA*40\n",
    "    #mean_Ridge = mean_Ridge*25*5.5\n",
    "\n",
    "    means = [mean_TA, mean_HA]#mean_HA, mean_Ridge]\n",
    "    stds = [std_TA*8.15, std_HA*40]#std_HA*40, std_Ridge*25*5.5]\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, lineopacity, legend_id):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    label_strings = ['Tail', 'Ridge', 'Hip', 'Ridge']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            mean_array[i] = mean_array[i][int_beg:int_end]#-mean_array[i][100]\n",
    "            x = np.linspace(-50, (len(mean_array[i]))/0.3, len(mean_array[i]))\n",
    "            ax.plot(x, mean_array[i], c=clrs[i], label = legend_id[i], alpha=lineopacity)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i][int_beg:int_end], mean_array[i]+std_array[i][int_beg:int_end], \\\n",
    "                            alpha=0.2, facecolor=clrs[i])\n",
    "            ax.legend(loc=\"upper right\", fontsize = 13, frameon=False)\n",
    "            ax.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "            #ax.axvline(100/300,0,360, color = 'red')\n",
    "            #ax.axvline(160,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key\n",
    "Xwidth_keys = ['4mm', '5mm', '8mm', '10mm']#, '30_deg']\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "list_means_AngMom = []\n",
    "list_std_AngMom = []\n",
    "list_TA_AngMom_conditions = []\n",
    "list_HA_AngMom_conditions = []\n",
    "dict_TA_AngMom_conditions = defaultdict(dict)\n",
    "#dict_HA_AngMom_conditions = defaultdict(dict)\n",
    "\n",
    "\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "    TA_traj_list, HA_traj_list, Ridge_traj_list, TA_traj_list_AngMom,  HA_traj_list_AngMom, pert_beg_idx_list = \\\n",
    "    plot_and_append_AngMomTraces(dict_percswings_widths[Xwidth_keys[i]], angmom_lowerinterv[i], \\\n",
    "                                 angmom_higherinterv[i], color_list[i])\n",
    "    means, stds = compute_AngMom_width(TA_traj_list, HA_traj_list)#HA_traj_list, Ridge_traj_list)\n",
    "    list_means_AngMom.append(means)\n",
    "    list_std_AngMom.append(stds)\n",
    "    list_TA_AngMom_conditions.append(TA_traj_list_AngMom)\n",
    "    list_HA_AngMom_conditions.append(HA_traj_list_AngMom)\n",
    "    dict_TA_AngMom_conditions[i] = [TA_traj_list_AngMom, HA_traj_list_AngMom]\n",
    "\n",
    "clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "mean_pert_traces = np.nanmean(TA_traj_list, axis = 0)\n",
    "x = np.linspace(0, 250/300, 249)\n",
    "#plt.plot(x, mean_pert_traces, color = clrs[0], linewidth = 4)\n",
    "plt.savefig('out.svg', format='svg', dpi=1200)\n",
    "plt.xlabel('Frame number (FR = 300 Hz)')\n",
    "plt.ylabel('Tail Angle (degrees))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_id = [['4mm TA', '4mm HA'], ['5mm TA', '5mm HA'], ['8mm TA', '8mm HA'], ['10mm TA', '10mm HA']]\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "lineopacity = [0.1, 0.4, 0.8, 1]\n",
    "\n",
    "for i in np.arange(len(list_means_AngMom)):\n",
    "    plot_PSTH_Mean_STD_label_color_pre_assigned(list_means_AngMom[i], list_std_AngMom[i], ax, lineopacity[i], legend_id[i])\n",
    "    print(np.trapz(list_means_AngMom[i]))\n",
    "    #ax1.scatter(list_HA_AngMom_conditions[i], list_TA_AngMom_conditions[i])\n",
    "    ax.set_xlabel('Time (s)', fontsize=18)\n",
    "    ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "plt.savefig('out.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Plot data figure 5 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AngMom_width(TA_traj_list, HA_traj_list, Ridge_traj_list):\n",
    "    mean_TA, std_TA = return_Mean_STD_forPSTH(TA_traj_list)\n",
    "    mean_HA, std_HA = return_Mean_STD_forPSTH(HA_traj_list)\n",
    "    mean_Ridge, std_Ridge = return_Mean_STD_forPSTH(Ridge_traj_list)\n",
    "\n",
    "    mean_TA = (mean_TA*8.15)\n",
    "    mean_HA=mean_HA*40\n",
    "    mean_Ridge = mean_Ridge*20*5.5\n",
    "\n",
    "    means = [mean_TA, mean_HA, mean_Ridge]\n",
    "    stds = [std_TA*8.15, std_HA*40, std_Ridge*20*5.5]\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, lineopacity, legend_id):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    label_strings = ['Tail', 'Ridge', 'Hip', 'Ridge']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, len(mean_array[i])/0.3, len(mean_array[i]))\n",
    "\n",
    "            mean_array[i] = mean_array[i]#-mean_array[i][100]\n",
    "            ax.plot(x, mean_array[i], c=clrs[i], label = legend_id[i], alpha=lineopacity)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.2, facecolor=clrs[i])\n",
    "            ax.legend(loc=\"lower left\")\n",
    "            ax.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "            #ax.axvline(100/300,0,360, color = 'red')\n",
    "            #ax.axvline(160,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot trials of same width together changing the dict_ridge_all key\n",
    "Xwidth_keys = ['4mm','5mm', '8mm', '10mm']#'10_deg','4mm', '30_deg']#'5mm', '8mm', '10mm']#, '30_deg']\n",
    "angmom_lowerinterv = [100, 100, 100, 100, 105, 105, 105]\n",
    "angmom_higherinterv = [150, 150, 150, 150, 150, 150]\n",
    "color_list = ['y', 'r', 'b', 'g']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "list_means_AngMom = []\n",
    "list_std_AngMom = []\n",
    "list_TA_AngMom_conditions = []\n",
    "list_HA_AngMom_conditions = []\n",
    "dict_TA_AngMom_conditions = defaultdict(dict)\n",
    "list_Ridge_AngMom_conditions = []\n",
    "\n",
    "\n",
    "for i in np.arange(len(Xwidth_keys)):\n",
    "    TA_traj_list, HA_traj_list, Ridge_traj_list, TA_traj_list_AngMom,  HA_traj_list_AngMom, pert_beg_idx_list = \\\n",
    "    plot_and_append_AngMomTraces(dict_percswings_widths[Xwidth_keys[i]], angmom_lowerinterv[i], \\\n",
    "                                 angmom_higherinterv[i], color_list[i])\n",
    "    means, stds = compute_AngMom_width(TA_traj_list, HA_traj_list, Ridge_traj_list)\n",
    "    list_means_AngMom.append(means)\n",
    "    list_std_AngMom.append(stds)\n",
    "    list_TA_AngMom_conditions.append(TA_traj_list_AngMom)\n",
    "    list_HA_AngMom_conditions.append(HA_traj_list_AngMom)\n",
    "    dict_TA_AngMom_conditions[i] = [TA_traj_list_AngMom, HA_traj_list_AngMom]\n",
    "    #list_Ridge_AngMom_conditions.append(Ridge_traj_list)\n",
    "\n",
    "\n",
    "#Compute mean of ang mom across widths for tail and hip and combination of both, and ridge\n",
    "tail_hip_ang_mom_mean = np.nanmean(list_means_AngMom, axis = 0)\n",
    "tail_hip_ang_mom_combined_mean = [tail_hip_ang_mom_mean[0], tail_hip_ang_mom_mean[1]]#, tail_hip_ang_mom_mean[0]+tail_hip_ang_mom_mean[1]]\n",
    "tail_hip_ang_mom_std = np.nanmean(list_std_AngMom, axis = 0)\n",
    "tail_hip_ang_mom_combined_std = [tail_hip_ang_mom_std[0], tail_hip_ang_mom_std[1]]#, tail_hip_ang_mom_std[0]+tail_hip_ang_mom_std[1]]\n",
    "Ridge_ang_mom_mean = tail_hip_ang_mom_mean[2]\n",
    "\n",
    "\n",
    "clrs = sns.color_palette(\"viridis\", n_colors=8)   \n",
    "mean_pert_traces = np.nanmean(TA_traj_list, axis = 0)\n",
    "#plt.plot(mean_pert_traces, color = clrs[0], linewidth = 4)\n",
    "plt.savefig('out.svg', format='svg', dpi=1200)\n",
    "plt.xlabel('Frame number (FR = 300 Hz)')\n",
    "plt.ylabel('Tail Angle (degrees))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_id = ['4mm TA', '4mm HA']#, 'jnnj']#[['4mm TA', '4mm HA'], ['5mm TA', '5mm HA'], ['8mm TA', '8mm HA'], ['10mm TA', '10mm HA']]\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "lineopacity = [0.1, 0.4, 0.8, 1]\n",
    "print(len(tail_hip_ang_mom_combined_mean))\n",
    "for i in np.arange(len(tail_hip_ang_mom_combined_mean)):\n",
    "    plot_PSTH_Mean_STD_label_color_pre_assigned(tail_hip_ang_mom_combined_mean, tail_hip_ang_mom_combined_std, ax, lineopacity[i], legend_id[i])\n",
    "    #print(np.trapz(list_means_AngMom[i]))\n",
    "#     x = np.linspace(0, 250/300, 249)\n",
    "#     plt.plot(x, Ridge_ang_mom_mean/2)\n",
    "    ax.set_xlabel('Time (ms)', fontsize=18)\n",
    "    ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "plt.savefig('out.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_SS, std_SS = return_Mean_STD_forPSTH(small_swing_list)\n",
    "# mean_MS, std_MS = return_Mean_STD_forPSTH(medium_swing_list)\n",
    "# mean_BS, std_BS = return_Mean_STD_forPSTH(big_swing_list)\n",
    "# means = [mean_SS, mean_MS, mean_BS]\n",
    "# stds = [std_SS, std_MS, std_BS]\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(12, 8))\n",
    "# clrs = sns.color_palette(\"husl\", 5)\n",
    "\n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(means, stds, ax)\n",
    "# # ax.set_xlim(50,200)\n",
    "# # ax.set_ylim(-1,3)\n",
    "# plt.savefig('sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
